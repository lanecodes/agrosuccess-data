{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Apply NLMpy's Random Cluster algorithm to study sites\n",
    "\n",
    "Script by the original authors to generate a neutral landscape model using the modified randon clusters algorithm can be found here [here](https://besjournals.onlinelibrary.wiley.com/action/downloadSupplement?doi=10.1111%2F2041-210X.12308&attachmentId=112210370)\n",
    "\n",
    "Original [paper](http://doi.org/10.1111/2041-210X.12308)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import subprocess\n",
    "import zipfile\n",
    "import re\n",
    "\n",
    "import requests\n",
    "\n",
    "from osgeo import gdal\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nlmpy import nlmpy\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = os.getcwd().split('/')[-1]\n",
    "in_landcover_nlms = pwd == 'landcover-nlms'\n",
    "TMP_DIR = Path('../tmp') if in_landcover_nlms else Path('tmp')\n",
    "OUTPUT_DIR = Path('../outputs') if in_landcover_nlms else Path('outputs')\n",
    "PLOTS_DIR = OUTPUT_DIR / 'plots'\n",
    "PLOTS_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script used by Etherington, Holland and O'Sullivan to produce Fig. 2 in their original [paper](http://doi.org/10.1111/2041-210X.12308) is retrieved and shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_url = 'https://besjournals.onlinelibrary.wiley.com/action/downloadSup'\\\n",
    "             'plement?doi=10.1111%2F2041-210X.12308&attachmentId=112210370'\n",
    "print(requests.get(script_url).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with NLMpy\n",
    "\n",
    "Objectives are to:\n",
    "1. Demonstrate how we can retrieve grids with proportions of landcover matching specified proportions \n",
    "2. Quantify error over possible solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nRow = 500\n",
    "nCol = 500\n",
    "rc_array = nlmpy.randomClusterNN(nRow, nCol, 0.58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(rc_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(rc_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_classified_even_array = nlmpy.classifyArray(rc_array, [0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(rc_classified_even_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(rc_classified_even_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_classified_even_array[:10, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(rc_classified_even_array, return_counts=True)\n",
    "n = nRow*nCol\n",
    "dict(zip(unique, counts/float(n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_classified_uneven_array = nlmpy.classifyArray(rc_array, [0.1, 0.8, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(rc_classified_uneven_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(rc_classified_uneven_array, return_counts=True)\n",
    "n = nRow*nCol\n",
    "dict(zip(unique, counts/float(n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_classified_uneven_array_shuffled = nlmpy.classifyArray(rc_array, [0.1, 0.1, 0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(rc_classified_uneven_array_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(rc_classified_uneven_array_shuffled, return_counts=True)\n",
    "n = nRow*nCol\n",
    "dict(zip(unique, counts/float(n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So** the list passed as the `weights` argument to nlmpy.classifyArray can be a list of proportions, and the class labels in the returned classified array correspond to the index of each provided wight.\n",
    "\n",
    "E.g. if we give the weights list `[0.1, 0.8, 0.1]` nlmpy.classifyArray will return an array where 10% of the elements are labelled `0`, 80%  are labelled `1` and 10% are labelled `2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DEM data from a GeoTiff file\n",
    "Etherington, Holland and O'Sullivan demonstrated `nlmpy`'s capability for integrating different NLMs for different elevation ranges using ASCIIGrid data. I will perform a similar analysis using a GeoTIFF file containing a DEM (STRM 1-second arc data) obtained using the notebook `download_site_elevation_data.html`.\n",
    "\n",
    "To extract a numpy array from the GeoTIFF file, we will make use of the [`rasterio`](https://pypi.org/project/rasterio) package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = os.getcwd().split('/')[-1]\n",
    "OUTPUT_DIR_ROOT = (Path('../outputs') \n",
    "                   if pwd == 'landcover-nlms' else Path('outputs'))\n",
    "TMP_DIR = Path('../tmp/') if pwd == 'landcover-nlms' else Path('tmp')\n",
    "test_site = 'navarres'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "navarres_dem_file = OUTPUT_DIR_ROOT / test_site / 'hydrocorrect_dem.tif'\n",
    "with rasterio.open(navarres_dem_file) as src:\n",
    "    dem = src.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(dem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to helping us to quickly plot our raster data, `rasterio` allows us to work with the DEM as a simple `numpy` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('type of raster object:', type(dem))\n",
    "print('shape of raster array:', dem.shape)\n",
    "print('array data type:', dem.dtype)\n",
    "print('a slice of the data:')\n",
    "print(dem[0,100:110,100:110])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first index of the returned `numpy` array describes the raster _band_. In the case of a DEM there is only one band: elevation in meters. However, as we shall see different types of raster data include several bands. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a satellite image to guide our design\n",
    "I'm imagining a plot which has satellite DEM, satelite image and proposed NLM next to each other for illustrative purposes. Satellite image will be needed to get an impression of land cover at that elevation in the present day.\n",
    "\n",
    "Focussing on the NavarrÃ©s study site as a starting point, we note it has the following lat/lon coordinates:\n",
    "- nav_lat = 39.1\n",
    "- nav_lon = -0.683333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to obtain landsat imagery\n",
    "- Go to USGS Earth Explorer \n",
    "- Search for the lat/lon coordinates given above, and a timeframe likely to have clear weather (i.e. a clear day)\n",
    "- Click on 'Sata Sets' tab\n",
    "- Select dataset Landsat > Landsat Collection 1 Level-1 > Landsat 8 OLI/TIRS C1 Level-1\n",
    "- Click 'Results'\n",
    "- Look for a thumbnail with little cloud cover\n",
    "- Click the 'download' icon for that scene\n",
    "- Select 'LandsatLook Images with Geographic Reference' option\n",
    "\n",
    "This downloads a zip containing, along with [other things](https://landsat.usgs.gov/landsatlook-images),  a natural color georeferenced image of the scene. The other things in the zip are a 'Quality' image (suffix \\_QB) used for e.g. detecting clouds, and 'Thermal' image (suffix \\_TIR) which we won't use in our analyses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip landsat image to the same extent as the DEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract LandsatLook image from zip file\n",
    "The LandsatLook images come in `.zip` files containing other data. We'll first temporarily extract the specific file we need to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_landsatlook_tif(zipfile_name, output_dir=None, output_name=None):\n",
    "    \"\"\"Extract a georeferenced LandsatLook tif from Earth Explorer zip file.\n",
    "    \n",
    "    Given a 'LandsatLook Images with Geographic Reference' zip file downloaded \n",
    "    from USGS Earth Explorer https://earthexplorer.usgs.gov, select the \n",
    "    Natural Colour .tif file and extract it to the specified output_dir, \n",
    "    naming it if given. Essentially this amounts to finding the file in the \n",
    "    zip archive which doesnt have a suffix indicating it's a 'Quality' image\n",
    "    (suffix _QB) or a 'Thermal' image (suffix _TIR).\n",
    "    \n",
    "    Args:\n",
    "        zipfile_name (str): Zipfile to be processed.\n",
    "        output_dir (Optional[str]): Path to directory in which to save \n",
    "            resulting tif file.\n",
    "        output_name (Optional[str]): Name to give output file.        \n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the output file.\n",
    "    \"\"\"\n",
    "    \n",
    "    with zipfile.ZipFile(zipfile_name, 'r') as z:\n",
    "        all_files = z.namelist()\n",
    "        natural_colour_files = [f for f in all_files \n",
    "                                if not(re.match(r'.*_QB.tif|.*_TIR.tif', f))]\n",
    "        if len(natural_colour_files) < 1:\n",
    "            raise ValueError('No Natural Colour .tif found in .zip')\n",
    "        elif len(natural_colour_files) > 1:\n",
    "            raise ValueError('{0} Natural Colour .tif files found in .zip '\\\n",
    "                             'when only one expected. Check file.')\n",
    "        else:\n",
    "            # Only if exactly one natural colour file identified, extract it\n",
    "            nc_file = natural_colour_files[0]\n",
    "            z.extract(nc_file, path=output_dir)\n",
    "            if (output_name and output_dir):\n",
    "                created_file = os.path.join(output_dir, output_name)\n",
    "                os.rename(os.path.join(output_dir, nc_file), created_file)\n",
    "            elif output_dir:\n",
    "                created_file = os.path.join(output_dir, nc_file)\n",
    "            elif output_name:\n",
    "                created_file = output_name\n",
    "                os.rename(nc_file, created_file)\n",
    "            else:\n",
    "                created_file = nc_file\n",
    "            \n",
    "            return created_file  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `gdalwarp` to do the clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_tif_extents(tif_to_match, tif_to_cut, output_name):\n",
    "    \"\"\"Use one tif file to crop another to the same extent and projection.\n",
    "    \n",
    "    Args:\n",
    "        tif_to_match (str): Name of a tif file to use as an example whose\n",
    "            extent and crs we want the other file to match.\n",
    "        tif_to_cut (str): Name of a tif file to crop and reproject to match\n",
    "            tif_to_match.\n",
    "        output_name (str): Name of resulting cropped and reprojected \n",
    "            tif file.\n",
    "            \n",
    "    Returns:\n",
    "        str: Path to the output file.   \n",
    "    \"\"\"\n",
    "    src_data = gdal.Open(tif_to_match, gdal.GA_ReadOnly)\n",
    "    wkt = src_data.GetProjection()\n",
    "    geoTransform = src_data.GetGeoTransform()\n",
    "    minx = geoTransform[0]\n",
    "    maxy = geoTransform[3]\n",
    "    maxx = minx + geoTransform[1] * src_data.RasterXSize\n",
    "    miny = maxy + geoTransform[5] * src_data.RasterYSize\n",
    "    src_data = None\n",
    "    \n",
    "    with open('tmp.prj', 'w') as prj:\n",
    "        # write a temporary well known text file to be used by gdalwarp\n",
    "        prj.write(wkt)\n",
    "       \n",
    "    # specify parameters to be passed to gdalwarp in an external process:\n",
    "    param = ['gdalwarp', tif_to_cut, output_name, '-overwrite',\n",
    "             '-t_srs', 'tmp.prj',\n",
    "             '-te', str(minx), str(miny), str(maxx), str(maxy)]\n",
    "    \n",
    "    cmd = ' '.join(param)\n",
    "    process = subprocess.check_call(cmd, shell=True)\n",
    "    \n",
    "    os.remove('tmp.prj')\n",
    "    \n",
    "    return output_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav_nc = extract_landsatlook_tif(\n",
    "    'data/LC08_L1TP_199033_20170730_20170811_01_T1.zip',\n",
    "    'data/',\n",
    "    'navarres_tmp.tif'\n",
    ")\n",
    "print(nav_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_tif_extents(str(navarres_dem_file), nav_nc, 'data/navarres_lsat.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open('data/navarres_lsat.tif') as src:\n",
    "    lsat = src.read()\n",
    "show(lsat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we find that the returned numpy array has three bands corresponding to Red, Green and Blue which the `rasterio.plot.show` function has conveniently worked out how to show in one image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of landsat image\\'s numpy array:', lsat.shape)\n",
    "\n",
    "print('\\nRed band slice:')\n",
    "print(lsat[0,100:110,100:110])\n",
    "\n",
    "print('\\nBlue band slice:')\n",
    "print(lsat[1,100:110,100:110])\n",
    "\n",
    "print('\\nGreen band slice:')\n",
    "print(lsat[2,100:110,100:110])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plot DEM and satellite image side-by side\n",
    "This will be a useful plot when deciding whether land cover proposed by Neutral Landscape model appears appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fs=18\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12,9) )\n",
    "show(dem, ax=ax1)\n",
    "ax1.set_axis_off()\n",
    "ax1.set_title('SRTM 1-sec arc', fontsize=fs)\n",
    "\n",
    "show(lsat, ax=ax2)\n",
    "ax2.set_axis_off()\n",
    "ax2.set_title('Landsat 8', fontsize=fs)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify initial condition land cover proportions for each study site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine initial vegetation proportions from pollen analysis\n",
    "Enforce the rule that the proportional area of land occupied by each land cover class in the NLM corresponds to the proportion of pollen corresponding to that vegetation type found in the sediment core for that study site.\n",
    "\n",
    "Note that this will need to be refined by incorporating the LRA, i.e. need to translate pollen _count_ to landscape _proportion_ in a more principled way. However, this will come later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load pollen time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_meta = (\n",
    "    pd.read_csv(OUTPUT_DIR_ROOT / 'site_metadata.csv').set_index('sitecode')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load land cover proportions from time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = (\n",
    "    pd.concat([\n",
    "        pd.read_csv(OUTPUT_DIR_ROOT / site / 'lct_pct_ts.csv')\n",
    "        .assign(sitecode=site) \n",
    "        for site in site_meta.index\n",
    "    ])\n",
    "    .set_index(['sitecode', 'agebp'])\n",
    "    .sort_index()\n",
    "    .filter(regex='^pct_*')  # Drop columns corresponding to derivatives\n",
    "    .rename(mapper=lambda s: s.replace('pct_', ''), axis='columns')\n",
    "    .divide(100)  # Convert percentage to proportion\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now we'll use only timeseries corresponding to the _proportion_ of counted pollen belonging to each landcover type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (ts.sum(1) - 1 < 0.00001).all(), (\n",
    "    'Land cover proportions sould sum to 1.'\n",
    ")\n",
    "\n",
    "ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our study sites are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# datapoints for included study sites:', ts.shape[0])\n",
    "print('# features for included study sites:', ts.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify $t_0$ years for each study site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssite_t0 = pd.Series({'navarres': 7000, \n",
    "                      'charco_da_candieira': 6500, \n",
    "                      'atxuri': 5000, \n",
    "                      'monte_areo_mire': 7300, \n",
    "                      'algendar': 5000, \n",
    "                      'san_rafael': 5000}).rename('t0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssite_t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These `t0` values correspond to the date at which it is belied humans first started practicing agriculture at each study site. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find land cover proportions at $t_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0_lct_props = ts.loc[zip(ssite_t0.index, ssite_t0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (site_code, year), lct_props in t0_lct_props.iterrows():\n",
    "    print(site_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9,5))\n",
    "t0_lct_props.plot(kind='bar', stacked=True, ax=ax)\n",
    "plt.legend(bbox_to_anchor=(.28,1.03), ncol=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save initial conditions to a temporary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0_lct_props.to_csv(TMP_DIR / 't0_lct_props.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify NLM model\n",
    "\n",
    "- Need to account for elevation, incorporating DEM. Account for existance of treeline\n",
    "- Also need to enforce the potentially conflicting criteria that the overall proportion of landcover should match the proportions specified in `t0_lct_props`.\n",
    "- The methods I'll be using are `nlmpy.randomClusterNN` to generate some random clusters with the right size, for above and below the treeline, `nlmpy.classifyArray` to assign clusters to the land cover classes with a weighting proportional to each lct's land cover proportions, and `np.where` to decide which part of the map will be characterised by the lowland NLM, and which part the highland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    t0_lct_props\n",
    "except NameError:\n",
    "    t0_lct_props = (\n",
    "        pd.read_csv(TMP_DIR / 't0_lct_props.csv')\n",
    "        .set_index(['sitecode', 'agebp'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick review of `nlmpy` capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@interact(perc_thresh=0.5, prop1=0.5, prop2=0.5)\n",
    "def make_500by500_MRC_array(perc_thresh, prop1, prop2):\n",
    "    nlm = nlmpy.randomClusterNN(500, 500, perc_thresh)\n",
    "    return plt.matshow(nlmpy.classifyArray(nlm, [prop1, prop2]), cmap='Set3')\n",
    "    \n",
    "make_500by500_MRC_array(0.6, 0.2, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up a test to evaluate the number of iterations required to gain acceptable solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm for obtaining a random clusters map involves first generating clusters using `nlmpy.randomClusterNN` before llocating these to categories matching desired proportions using `nlmpy.classifyArray`. This means there is some variance in how successful the algorithm is at matching the reuested proportions. Below I run a test to evaluate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_array(nRow, nCol, target_proportions, perc_threshold):\n",
    "    test = nlmpy.randomClusterNN(nRow, nCol, perc_threshold)\n",
    "    test = nlmpy.classifyArray(test, target_proportions)\n",
    "    return test   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_random_clusters_accuracy(target_proportions, perc_threshold, no_iterations=100):\n",
    "    \"\"\"Return overall root mean square error.\n",
    "    \n",
    "    Construct `no_iterations` landscapes using the target proportions and \n",
    "    percolation threshold given. Compare the landcover proportions in the \n",
    "    resulting landscape with the target proportions, constructing a root mean\n",
    "    square error as a score.\n",
    "    \n",
    "    \"\"\"\n",
    "    N = 500 # approximate size of DEMs for study site\n",
    "    N2 = N*N\n",
    "    res = np.empty((no_iterations, len(target_proportions)))\n",
    "    for i in range(no_iterations):\n",
    "        # make a test array\n",
    "        a = generate_test_array(N, N, target_proportions, perc_threshold)\n",
    "        output_props = []\n",
    "        for val in np.unique(a):\n",
    "            # calculate the proportion of each land cover type in test array\n",
    "            output_props.append((a==val).sum()/float(N2))\n",
    "        # find square of differences between test array's proportions and\n",
    "        # target proportions\n",
    "        try:\n",
    "            res[i,:] = np.power(np.array(target_proportions) - np.array(output_props), 2)        \n",
    "        except ValueError:\n",
    "            'target proportions: {0}\\nperc_threshold: {1}\\nno iterations: {2}\\n'\\\n",
    "            'output proportions: {3}\\n'.format(target_proportions, \n",
    "                                               perc_threshold, \n",
    "                                               no_iterations, \n",
    "                                               output_props)\n",
    "\n",
    "        \n",
    "    # sum up errors across all proportions\n",
    "    res = res.sum()/float(N2)\n",
    "    # take square root\n",
    "    res = np.sqrt(res)        \n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MRC_RMSE(result_array, target_props):\n",
    "    \"\"\"Find error in MRC array vs target proportions.\n",
    "    \n",
    "    Calculates the proportion of an array allocated to each class and \n",
    "    calculates the RMS error across classes to give the resulting array \n",
    "    a score on the basis of its ability to reproduce the required land\n",
    "    cover characteristics.\n",
    "    \"\"\"\n",
    "    target_props = np.array(target_props)\n",
    "    # total number of entries\n",
    "    N = result_array.size\n",
    "    classes = np.unique(result_array)\n",
    "    if classes.shape != target_props.shape:\n",
    "        raise ValueError('# classes in array don\\'t match # requested '\\\n",
    "                         'proportions.')\n",
    "    result_props = []\n",
    "    for val in classes:\n",
    "        # calculate proportion of array belonging to each class\n",
    "        result_props.append((result_array==val).sum()/float(N))\n",
    "    result_props = np.array(result_props)\n",
    "    #rmse calculation\n",
    "    rmse = np.sqrt(np.power(target_props-result_props,2).sum()/target_props.shape[0])   \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify proportion scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_scenarios = {\n",
    "    '2_similar': [0.5, 0.5],\n",
    "    '2_different': [0.1, 0.9],\n",
    "    '4_similar': [0.25, 0.25, 0.25, 0.25],\n",
    "    '4_different': [0.1, 0.3, 0.5, 0.1],    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the different numbers of iterations to try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = np.arange(10,51)\n",
    "iterations = iterations[iterations%10==0]\n",
    "print(iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percolation_thresholds = np.array([0.1, 0.5, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_MRC_algorithm_prop_accuracy():\n",
    "    df = pd.DataFrame(columns=['prop_scenario', 'no_iterations', 'perc_thresh', 'RMSE'])\n",
    "    this_idx = 0\n",
    "    for scenario, proportions in prop_scenarios.iteritems():\n",
    "        for iteration in iterations:\n",
    "            for perc in percolation_thresholds:\n",
    "                r = test_random_clusters_accuracy(proportions, perc, no_iterations=iteration)\n",
    "                df.loc[this_idx] = [scenario, iteration, perc, r]\n",
    "                print(df.loc[this_idx])\n",
    "                this_idx += 1\n",
    "                \n",
    "run=False\n",
    "if run:\n",
    "    test_MRC_algorithm_prop_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the algorithm produces good results in all scenarios tested, except a small number which did really badly. Both of these belong to the `4_different` proportion scenario with a high percolation threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run:\n",
    "    print(df[df.RMSE>1])\n",
    "    print(df[df.prop_scenario=='4_different'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly runs 17, 20 and 23 show the same parameters being run, with fewer iterations, and with good results. I think the lesson here is to keep an eye on the performance of the MRC algorithm in `nlmpy` but not to worry about super high iterations too much.\n",
    "\n",
    "As can be seen below, the problem seems to be that with very high percolation thresholds, the algorithm finds it difficult to assign any patches to some land cover types, resulting in bad results. It's high percolation thresholds which is the problem, rather than the number of land cover types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = generate_test_array(500, 500, [0.1, 0.9], 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(t, cmap='Set3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform overall landcover proportions to highland and lowland allocations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data gives us the overall proportion of landcover around each study site at $t_0$. However, it would be useful to be able to specify different distributions of landcover above and below the treeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define $N^{\\text{tot}}$ as the total number of cells in the model. We can separate these cells into components contributed by each of the land-cover classes represented in the model such that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "N^{\\text{tot}} = N^{\\text{tot}}(\\mathbf{C}) = \\sum_c N_c(\\mathbf{C})\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where we define $N_c(\\mathbf{C})$ as the number of cells in class $c \\in \\{\\text{oak forest}, \\text{shrubland}\\dots\\}$. The land-cover class matrix $\\mathbf{C}$ has elements $c_{ij}$ encoding the land cover class of the cell in position $(i,j) : i \\in (1, \\dots, N_y),\\, j\\in (1, \\dots, N_x)$. In symbols,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "N_c(\\mathbf{C}) = \\sum_{i=1}^{N_y} \\sum_{j=1}^{N_x} \\delta_{c_{ij}, c} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of cells in class $c$, $N_c(\\mathbf{C})$, can be further divided into $N^{\\text{hi}}_c(\\mathbf{C}, \\mathbf{E}; \\epsilon) $ and $N^{\\text{lo}}_c(\\mathbf{C}, \\mathbf{E}; \\epsilon)$ -- the number of cells in class $c$ which are above and below the treeline respectively. The matrix $\\mathbf{E}$ has elements $e_{ij}$ which encode the elevation of the DEM cell in position $(i,j) : i \\in (1, \\dots, N_y),\\, j\\in (1, \\dots, N_x)$. The parameter $\\epsilon$ is the elevation of the treeline and is study site dependent(?). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "N_c(\\mathbf{C}) = N^{\\text{hi}}_c(\\mathbf{C}, \\mathbf{E}; \\epsilon) + N^{\\text{lo}}_c(\\mathbf{C}, \\mathbf{E}; \\epsilon)\\\\\n",
    "N^{\\text{hi}}_c(\\mathbf{C}, \\mathbf{E}; \\epsilon) = \\sum_{i=1}^{N_y} \\sum_{j=1}^{N_x} \\delta_{c_{ij}, c}\\, \\Theta(e_{ij} - \\epsilon)\\\\\n",
    "N^{\\text{lo}}_c(\\mathbf{C}, \\mathbf{E}; \\epsilon) = \\sum_{i=1}^{N_y} \\sum_{j=1}^{N_x} \\delta_{c_{ij}, c}\\, \\left[1 - \\Theta(e_{ij} - \\epsilon) \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, $\\Theta(n)$ is the Heaviside step function defined such that \n",
    "$$\\Theta(n)=\n",
    "\\begin{cases}\n",
    "    0,\\; n<0 \\\\\n",
    "    1,\\; n\\geq0\n",
    "\\end{cases}\\,.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our data is expressed in terms of _proportions_ of land-cover occupied by each class, we define $\\rho_c=N_c/N^{\\text{tot}}$ (total proportion of land-cover occupied by class $c$), and $\\rho^{\\text{hi}}_c=N^{\\text{hi}}_c/N^{\\text{hi}}$ and $\\rho^{\\text{lo}}_c=N^{\\text{lo}}_c/N^{\\text{lo}}$ (proportions of cells in class $c$ above and below the treeline respectively). Here $N^{\\text{hi}} = \\sum_c N^{\\text{hi}}_c$ and $N^{\\text{lo}} = \\sum_c N^{\\text{lo}}_c$. Note $\\sum_c\\rho^{\\text{hi}}_c = \\sum_c\\rho^{\\text{lo}}_c =1$. We have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\rho^{\\text{hi}}_c(\\mathbf{C}, \\mathbf{E}; \\epsilon) = \\frac{1}{N^{\\text{hi}}}\\sum_{i=1}^{N_y} \\sum_{j=1}^{N_x} \\delta_{c_{ij}, c}\\, \\Theta(e_{ij} - \\epsilon)\\\\\n",
    "\\rho^{\\text{lo}}_c(\\mathbf{C}, \\mathbf{E}; \\epsilon) = \\frac{1}{N^{\\text{lo}}} \\sum_{i=1}^{N_y} \\sum_{j=1}^{N_x} \\delta_{c_{ij}, c}\\, \\left[1 - \\Theta(e_{ij} - \\epsilon) \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know the value of $\\rho_c$ for each $c$ from our data. It will be useful to be able to specify, aspart of our model, the relatively simple proportion of each land-cover type occupying the area above the treeline (e.g. 100% shrubland), and calculate the lowland proportions which preserve our target global land cover proportions, $\\rho_c$. We can derive an equationto do this based on the quantities defined above:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "N_c = N_c^{\\text{hi}} + N_c^{\\text{lo}}\\\\\n",
    "N^{\\text{tot}}\\rho_c = N^{\\text{hi}}\\rho^{\\text{hi}}_c + N^{\\text{lo}}\\rho^{\\text{lo}}_c \\\\\n",
    "\\implies \\rho^{\\text{lo}}_c(\\mathbf{E}, \\rho_c, \\rho^{\\text{hi}}_c; \\epsilon) = \\frac{N^{\\text{tot}}(\\mathbf{E}) \\,\\rho_c- N^{\\text{hi}}(\\mathbf{E};\\epsilon)\\,  \\rho^{\\text{hi}}_c}{N^{\\text{lo}}(\\mathbf{E};\\epsilon)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also note \n",
    "$$\n",
    "N^{\\text{hi}}(\\mathbf{E}; \\epsilon) = \\sum_{i=1}^{N_y} \\sum_{j=1}^{N_x} \\Theta(e_{ij} - \\epsilon)\\\\\n",
    "N^{\\text{lo}}(\\mathbf{E}; \\epsilon) = \\sum_{i=1}^{N_y} \\sum_{j=1}^{N_x} \\left[1 - \\Theta(e_{ij} - \\epsilon) \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define python functions to perform this calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_N_tot(dem_array):\n",
    "    \"\"\"Get the number of cells in a DEM passed as a numpy.ndarray\"\"\"\n",
    "    return dem_array.size\n",
    "\n",
    "def get_N_hi(dem_array, epsilon):\n",
    "    \"\"\"Get number of cells above the tree line in dem_array.\"\"\"\n",
    "    return dem_array[dem_array>=epsilon].size\n",
    "\n",
    "def get_N_lo(dem_array, epsilon):\n",
    "    \"\"\"Get number of cells below or on the tree line in dem_array.\"\"\"\n",
    "    return dem_array[dem_array<epsilon].size\n",
    "\n",
    "def get_rho_c_lo(dem_array, rho_c, rho_c_hi, epsilon):\n",
    "    \"\"\"Calculate rho_c_lo using DEM, data and upland land-cover proportion.\"\"\"\n",
    "    num = get_N_tot(dem_array)*rho_c - get_N_hi(dem_array, epsilon)*rho_c_hi\n",
    "    den = get_N_lo(dem_array, epsilon)\n",
    "    return float(num)/den"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function to get the lowland land-cover proportions given an iterable of highland land-cover proportions, and an iterable of overall land-cover proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowland_props(dem_array, rho_c_s, rho_c_hi_s, epsilon):\n",
    "    \"\"\"Calculate lowland land-cover proportions given highland and totals.\n",
    "    \n",
    "    Args:\n",
    "        dem_array (numpy.array): Digital Elevation Model used to distinguish\n",
    "            highland areas from lowland.\n",
    "        rho_c_s (list of float): Overall land cover proportions, one float per\n",
    "            land cover type label.\n",
    "        rho_c_hi_s (list of float): Land cover proportions in the highlands\n",
    "        epsilon (int): Elevation of the tree line\n",
    "        \n",
    "    Returns:\n",
    "        list of floats: the land cover proportions in the lowlands consistent\n",
    "            with having rho_c_s overall and rho_c_hi_s in the highlands.        \n",
    "            \n",
    "    \"\"\"\n",
    "    def get_N_tot(dem_array):\n",
    "        \"\"\"Get the number of cells in a DEM passed as a numpy.ndarray\"\"\"\n",
    "        return dem_array.size\n",
    "    \n",
    "    def get_N_hi(dem_array, epsilon):\n",
    "        \"\"\"Get number of cells above the tree line in dem_array.\"\"\"\n",
    "        return dem_array[dem_array>=epsilon].size\n",
    "    \n",
    "    def get_N_lo(dem_array, epsilon):\n",
    "        \"\"\"Get number of cells below or on the tree line in dem_array.\"\"\"\n",
    "        return dem_array[dem_array<epsilon].size\n",
    "    \n",
    "    def get_rho_c_lo(dem_array, rho_c, rho_c_hi, epsilon):\n",
    "        \"\"\"Calculate rho_c_lo using DEM, data and upland land-cover proportion.\"\"\"\n",
    "        num = get_N_tot(dem_array)*rho_c - get_N_hi(dem_array, epsilon)*rho_c_hi\n",
    "        \n",
    "        if num < 0:\n",
    "            raise ValueError('rho_c_lo results in negative lowland proportion' \\\n",
    "                            ' of landcover. Reduce proportion in highland.')\n",
    "        den = get_N_lo(dem_array, epsilon)\n",
    "        return float(num)/den    \n",
    "    \n",
    "    num_rho_c = len(rho_c_s)\n",
    "    if num_rho_c != len(rho_c_hi_s):\n",
    "        raise ValueError('Numbers of provided total land-cover proportions '\\\n",
    "                'and specified highland proportions must match.')\n",
    "        \n",
    "    rho_c_lo_s = []\n",
    "    for i in range(num_rho_c):\n",
    "        rho_c_lo_s.append(get_rho_c_lo(dem_array, rho_c_s[i], rho_c_hi_s[i], epsilon))   \n",
    "        \n",
    "    return rho_c_lo_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on DEM data for Navarres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "navarres_dem_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(navarres_dem_file) as src:\n",
    "    dem = src.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('initial DEM shape:', dem.shape)\n",
    "print('extract the only layer in the dataset')\n",
    "dem = dem[0, :, :]\n",
    "print('final DEM shape:', dem.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A look at the distribution of elevations suggests a value of 400 might be a sensible first guess for what we consider uplands. Let's set $\\epsilon=400$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dem.flatten());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting our land-cover initial conditions from `ssite_t0` we confirm they are in the order deciduous_forest, oak_forest, pine_forest, shrubland in the array returned from the series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t0_lct_props.loc['navarres'], '\\n')\n",
    "rho_c = t0_lct_props.loc['navarres'].values[0, :]\n",
    "print(rho_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First guess at upland land-cover proportions is that all uplands are occupued by shrubland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_c_hi = [0.0, 0.0, 0.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_c_lo = lowland_props(dem, rho_c, rho_c_hi, eps)\n",
    "print(rho_c_lo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlm_lo = nlmpy.randomClusterNN(dem.shape[0], dem.shape[1], 0.59)\n",
    "nlm_lo = (nlmpy.classifyArray(nlm_lo, rho_c_lo)\n",
    "          .astype('int16'))\n",
    "# relabel values, assuming same order as in proportion list\n",
    "nlm_lo = np.where(nlm_lo==0, 1, nlm_lo) # to do with data type, switch to int? \n",
    "\n",
    "nlm_hi = nlmpy.randomClusterNN(dem.shape[0], dem.shape[1], 0.5)\n",
    "nlm_hi = (nlmpy.classifyArray(nlm_hi, rho_c_hi)\n",
    "          .astype('int16'))\n",
    "# relabel so shrubland values match up between high and low arrays\n",
    "nlm_hi = np.where(nlm_hi==0, 3, nlm_hi)\n",
    "\n",
    "nlm = np.where(dem < eps, nlm_lo, nlm_hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(nlm_lo))\n",
    "print(np.unique(nlm_hi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "components with proportion 0 aren't represented in classification. Want the following:\n",
    "- 0: deciduous_forest\n",
    "- 1: oak_forest\n",
    "- 2: pine_forest\n",
    "- 3: shrubland "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get landsat image\n",
    "with rasterio.open('data/navarres_lsat.tif') as src:\n",
    "    lsat = src.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot DEM, lsat and nlm together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 18\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(12, 5))\n",
    "show(dem, ax=ax1)\n",
    "ax1.set_axis_off()\n",
    "ax1.set_title('SRTM 1-sec arc', fontsize=fs)\n",
    "\n",
    "show(lsat, ax=ax2)\n",
    "ax2.set_axis_off()\n",
    "ax2.set_title('Landsat 8', fontsize=fs)\n",
    "\n",
    "ax3.matshow(nlm, cmap='Set3')\n",
    "ax3.set_axis_off()\n",
    "ax3.set_title('NLM', fontsize=fs)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOTS_DIR / 'navarres_dem_landsat8_nlm.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose treeline for sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different sites are going to need different treelines are some are close to the coast etc. Plot distribution of elevations for each study site:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raster_array(raster_file: Path) -> np.array:    \n",
    "    with rasterio.open(raster_file) as src:\n",
    "        dem = src.read()\n",
    "    return dem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges = np.arange(0, 2200, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_hists = (\n",
    "    pd.DataFrame({\n",
    "        site_name: np.histogram(\n",
    "            get_raster_array(\n",
    "                OUTPUT_DIR_ROOT / site_name / 'hydrocorrect_dem.tif'\n",
    "            ),\n",
    "            bins=bin_edges,\n",
    "            density=True,\n",
    "        )[0] \n",
    "        for site_name in site_meta.index\n",
    "    }, index=pd.IntervalIndex.from_breaks(bin_edges))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, nrows=2, figsize=(9, 5))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    s = dem_hists.iloc[:, i]\n",
    "    s.plot.bar(ax=ax)\n",
    "    ax.set_title(s.name)\n",
    "    ax.set_xticklabels([x for x in s.index], rotation=45, ha='right')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "name": "navarres_modified_random_clusters.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
