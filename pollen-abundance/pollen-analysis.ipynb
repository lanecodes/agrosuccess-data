{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstructing the land-cover of prehistoric landscapes\n",
    "\n",
    "The purpose of this notebook is to :\n",
    "1. Extract pollen abundance time-series data from a locally running instance of the European Pollen Database for a selection of sites I am studying in the development of my PhD thesis.\n",
    "2. Explore, consider the limitations of, and clean that data.\n",
    "3. Support the systematic assignment of pollen types identified in the empirical data to the categorical land-cover types which will be represented in my simulation models. This is a form of modelling in itself, and serves as an abstraction couched in terms of the notion of a plant functional type. That is, plant _species_ which are postulated to be functionally identical as far as the model is concerned are assigned to the same plant functional group. This will be achieved using regular expressions to embelish the data in a pandas dataframe.\n",
    "4. Apply the Landscape Reconstruction Algorithm (LRA) to the pollen abundance data to infer the _proportion_ of landscape occupied from each plant functional group.\n",
    "5. Produce, for each of my empirical study sites, time-series of the proportion of landscape occupied for each of the functional groups represented in the model for the duration of time for which there is abundance data for each study site. This will be presented in the form of a `.csv` file and a plot for each study site. \n",
    "\n",
    "The only input required to run this notebook is a connection to the European Pollen Database (and access to dependencies including `pyogeo`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "sys.path.insert(0, \"/home/andrew/Documents/codes/python/gis/\")\n",
    "import pyogeo as pg # note this only works if notebook sterver started with bash\n",
    "from pyogeo.pollendat import PollenCore\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "mpl.rcParams['font.family'] = 'CMU Sans Serif'\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#import seaborn as sns\n",
    "from ipywidgets import interact, fixed\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extract data for sudy sites from the EPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd = pg.EPD(con=create_engine(\n",
    "    'postgresql://andrew:password@localhost:5432/epd95'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\n",
    "    'postgresql://andrew:password@localhost:5432/epd95'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relate pollen cores to study sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a dictionary to hold names and EPD site numbers of sites under consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_dict = {# original selection presented in checkpoint report\n",
    "             'Sanabria Marsh' : 44,\n",
    "             'Albufera Alcudia' : 759,\n",
    "             'Laguna Guallar' : 761,\n",
    "             'San Rafael' : 486,\n",
    "             'Navarr√©s' : 396,\n",
    "             'Monte Areo mire' : 1252,\n",
    "             # additional sites Carrion2010 called outstanding\n",
    "             # examples of sites with anthropogenic disturbance             \n",
    "             'Atxuri' : 76, # neolithic\n",
    "             'Puerto de Los Tornos' : 560, # neolithic\n",
    "             'Charco da Candieira' : 762, # neolithic\n",
    "             'Bajondillo' : 1260, # neolithic\n",
    "             'Algendar' : 55 # Bronze age, Minorca\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load sites under consisideration into EPD object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd.ssites = list(site_dict.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get pollen cores for each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_cores(epd):\n",
    "    WHERE_CLAUSE = 'WHERE '+' OR '.join(['site_='+str(s) for s in epd.ssites])\n",
    "    query = \"SELECT * FROM entity \"+WHERE_CLAUSE+\";\"\n",
    "    print('running query:\\n'+query)\n",
    "    res = epd.run_sql(query)\n",
    "    res = res[['e_', 'site_', 'sigle', 'name', 'entloc', 'notes']]\n",
    "    return res.set_index('e_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = get_available_cores(epd)\n",
    "cores = cores.join(epd.get_site_loc_info(), on='site_')\n",
    "cores = cores.drop(['sitecode', 'siteexists', 'poldiv1', 'poldiv2', \n",
    "                  'latdms', 'londeg', 'lonmin', 'lonsec', 'lonew', \n",
    "                  'londms', 'poldiv3', 'latdeg', 'latmin', 'latsec', \n",
    "                  'latns', 'areaofsite'], axis=1)\n",
    "cores = cores[['site_', 'sitename', 'sigle', 'name', 'latdd', \n",
    "               'londd', 'elevation', 'entloc', 'notes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores.reset_index().groupby(by=['e_', 'site_']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save list of cores to csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores.to_csv('entity_info.csv', encoding='utf8', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore, condider the limitations of, and clean pollen core data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check numbers of samples in each core, narrow core selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data for one of the two Navarres cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav = PollenCore(469, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav_dat = nav.get_all_pollen_chronology()\n",
    "print(nav_dat.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note `pollen_pct` is a derived column [check what this means in the EPD documentation], and it potentially not on the most well founded basis as we shall see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print nav_dat.sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that much of the pollen recorded in the database for this sediment core corresponds to [pollen spike](https://quantpalaeo.wordpress.com/2017/07/28/pollen-spikes/), with `varcode=conc.spk`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nav_dat[nav_dat.varcode=='conc.spk']['count'].plot()\n",
    "nav_dat.sample_.unique()\n",
    "#nav_dat[nav_dat.varcode=='conc.spk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More troublingly, navares core 469, NAVA1 has only 15 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav2 = PollenCore(470, engine)\n",
    "nav2.get_all_pollen_chronology().sample_.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav3 = PollenCore(471, engine)\n",
    "nav3.get_all_pollen_chronology().sample_.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going forward, I'll prefer NAVA3 over NAVA1 and NAVA2 since it contains more samples. If I find something which makes NAVA3 seem iffy, I may reconsider. For now, drop NAVA1 and NAVA2 from the `cores` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = cores.drop([469, 470], axis=0)\n",
    "cores.to_csv('entity_info.csv', encoding='utf8', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract sediment core data for each study site from the EPD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load cores from csv file created in the previous secion if it isn't already in the namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'cores' in locals():\n",
    "    cores = pd.read_csv('entity_info.csv', encoding='utf8')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make empty template for master chronology DF\n",
    "cols = list(PollenCore(471, engine).get_all_pollen_chronology().columns.values)\n",
    "cols.extend(('site_', 'sitename')) # additional cols for master df vs single entity ones\n",
    "chrons = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i, row in cores.iterrows():\n",
    "    df = PollenCore(i, engine).get_all_pollen_chronology()\n",
    "    df['site_'] = int(row.site_)\n",
    "    df['sitename'] = row.sitename\n",
    "    chrons = chrons.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in chrons.columns:\n",
    "    print c+': '+str(chrons[c].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chron_dtypes = {'e_':'int', 'sample_':'int', 'var_':'int', 'site_':'int', \n",
    "                'count':'int'}\n",
    "for k in chron_dtypes.keys():\n",
    "    chrons[k] = chrons[k].astype(chron_dtypes[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chrons = chrons.drop('pollen_pct', axis=1)\n",
    "chrons.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at top ten pollen contributing species for each study site, remove sediment spike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_species():\n",
    "    for ssite in chrons.sitename.unique():\n",
    "        print '\\n'+ssite\n",
    "        df = chrons[chrons.sitename==ssite]\n",
    "        df = df.groupby(['var_', 'varcode', 'varname']).agg({'count' : 'sum'})\n",
    "        print df.sort_values(by='count', ascending=False).head(5)\n",
    "    del df\n",
    "\n",
    "print_top_species()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navarres alone seems to have a lot of pollen spike in it. Also Monte Areo mire and Charco da Candieira have Lycopodium added. To keep analyses between sites consistent, I will exclude these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_pollen_spike = True\n",
    "if exclude_pollen_spike:\n",
    "    not_spike = (chrons.varcode<>'Spi/tab') & (chrons.varcode<>'Lyc(ad)') & (chrons.varcode<>'Lyc(ct)') & (chrons.varcode<>'Lyc')\n",
    "    chrons = chrons[not_spike]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also note that San Rafael has a significant proportion of Botryococcus in its samples. This is a type of green algae. Since this doesn't correspond to any _land_ plant species, we exclude it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_non_land_plants = True\n",
    "if exclude_non_land_plants:\n",
    "    land_plants = ((chrons.varcode<>'Bry') & \n",
    "                   (chrons.varcode<>'Zyg-T') & \n",
    "                   (chrons.varcode<>'Spr-T') &\n",
    "                   (chrons.varcode<>'Pot') & #Potamogeton, aquatic plant\n",
    "                   (chrons.varcode<>'Clo.i-T') & # Closterium idiosporum, green algae                   \n",
    "                   (chrons.varcode<>'Spi.cf.s') & #Spirogyra cf. scrobiculata, green algae\n",
    "                   (chrons.varcode<>'Trl.s') # Trilete spore(s),  not from modern terrestrial plant\n",
    "                   )\n",
    "    chrons = chrons[land_plants]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identified lots of moss (Sphagnum) in, e.g. Atxuri. Exclude this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_mosses = True\n",
    "if exclude_mosses:\n",
    "    not_moss = (chrons.varcode<>'Sph')\n",
    "    chrons = chrons[not_moss]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungal spores such as Glomus turn up in Navarres. Exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_fungi = True\n",
    "if exclude_fungi:\n",
    "    not_fungus = ((chrons.varcode<>'Glomus') &\n",
    "                  (chrons.varcode<>'Pos') # Polyadosporites, fungal spore http://www.redalyc.org/html/454/45437346003/index.html\n",
    "                 )\n",
    "    chrons = chrons[not_fungus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove records corresponding to pollen which could not be identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_unrecognised = True\n",
    "if exclude_unrecognised:\n",
    "    identified = ((chrons.varcode<>'Ind.unkn') & #found in navarres\n",
    "                  (chrons.varcode<>'T16C')\n",
    "                  )\n",
    "    chrons = chrons[identified]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECK Recalculate pollen percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, `chrons` contains entries for all:\n",
    "1. sediment cores\n",
    "2. samples (depths/ ages)\n",
    "3. species (careful to exclude pollen spike\n",
    "\n",
    "To convert absolute abundances to percentages for plotting, we will need total pollen counts for each sample, for each entity.\n",
    "\n",
    "The `pollen_pct` column was a derived column in the database, so we should check if it matches our understanding of percentage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframe containing totals for each entity and sample\n",
    "tot_pollen = chrons.groupby(['e_','sample_']).agg({'count' : 'sum'})\n",
    "# join totals back into chrons\n",
    "chrons = chrons.join(tot_pollen, on=['e_', 'sample_'], rsuffix='_sample_tot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrons.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# givethe total count for site column a catchier name\n",
    "chrons = chrons.rename(columns={'count_sample_tot':'tot_count_for_site'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrons.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate `my_pollen_pct` as a reperformance of the derived value `pollen_pct` in the EPD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrons['my_pollen_pct'] = chrons['count']/chrons.tot_count_for_site*100\n",
    "chrons['pollen_pct_diff'] = chrons.pollen_pct - chrons.my_pollen_pct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate staistics on rows which do/ don't match my calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_no_samples = len(chrons.index)\n",
    "matches = chrons[chrons.pollen_pct_diff==0]\n",
    "num_matches = len(matches.index)\n",
    "print 'Out of a total of {0} samples, my calculation of pollen percentage '\\\n",
    "    'matches EPD calc in {1} instances ({2:.1f}%)'.format(tot_no_samples,\n",
    "                                                      num_matches,\n",
    "                                                      float(num_matches)/tot_no_samples*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching rows came from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.sitename.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at rows which don't match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doesnt_match = chrons[chrons.pollen_pct_diff<>0]\n",
    "doesnt_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doesnt_match.sitename.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rember that Navarres, Monte Areo mire and Charco da Candieira were the sites which had pollen spike/ lycopodium excluded. Notice how if we change `exclude_pollen_spike` to `False` above, my recalculated values match those reported in the EPD. This confirms that the discrepancy is caused by excluding pollen spike.\n",
    "\n",
    "Repeating this calculation gives me confidence that I've retrieved all samples for each site, and that I am calculating pollen percentage properly using the total number of pollen counted per (site, core, sample) combination to divide each (site, core, sample) species' count.\n",
    "\n",
    "As I don't believe at this time that I should include pollen spikes in my counts/ don't know how use them yet (see [here](https://palynology.wordpress.com/2012/10/07/pollen-spike/) for background), I'll continue having excluded them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean `chrons` dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having assured ourselves of the correctness of the pollen counts we can clean up this dataframe somewhat. Since our end result will consider the proportions of landscape occupied by different PFTs, we won't be using the percentages of individual species contributing to each sample, so we can drop all these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrons = chrons.drop([c for c in chrons.columns if re.match(r'.*pollen_pct.*', c)], axis=1)\n",
    "chrons.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need the total count per site either as this is easy to recalculate an is unnecessary duplicated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrons = chrons.drop('tot_count_for_site', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Give each site an easily typed `sitecode` to refer to as an index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be convenient to be able to refer to sites as an index. To make these easy to type, create a `sitecode` column which strips out spaces and removes any unicode names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "chrons['sitecode'] = chrons.sitename.apply(unidecode.unidecode)\n",
    "chrons['sitecode'] = chrons.sitecode.str.replace(' ', '_')\n",
    "chrons['sitecode'] = chrons.sitecode.str.lower()\n",
    "print chrons.sitecode.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrons.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I plan to use `sitename` as an index going forward because it's natural to think in terms of study sites. This means I don't need other information in the dataframe I take forward in my analyses at the study site level of detail. So this information can easily be rerieved if needs be when debugging, I save this to disk and remove the extra columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_metadata = chrons[['site_', 'sitename', 'sitecode']].drop_duplicates()\n",
    "site_metadata.to_csv('site_metadata.csv', encoding='utf8', index=False)\n",
    "site_metadata = None \n",
    "chrons = chrons.drop(['site_', 'sitename'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sample_` (a database key from the EPD) is also redundant at this point, since we can idenify each sample from its `agebp`. Similarly each variable (pollen species) is uniquely identified by its `varcode` so we can also drop `var_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(chrons.var_.index)\n",
    "print len(chrons.varcode.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrons = chrons.drop(['sample_', 'var_'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrons = chrons.set_index(['sitecode', 'e_', 'agebp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print chrons.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename `count` to avoid an understandable but irritating namespace collision with the `pd.Series.count` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrons = chrons.rename(columns={'count': 'pcount'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print chrons.loc['navarres'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print chrons.groupby(level=[0,1]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`chrons` is now prepped and ready to use for subsequent analyses. Serialise a a `pickle` file so it can be retrieved without rerunning the above cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrons.to_pickle('chrons.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TODO Relate identified pollen species with model-dependent plant functional types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify land-cover types with pollen species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'chrons' not in locals():\n",
    "    import pandas as pd\n",
    "    import re\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    \n",
    "    chrons = pd.read_pickle('chrons.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve a list of unique `varname`-s found amongst the sediment cores analysed thus far in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_species = chrons[['varname', 'varcode']].drop_duplicates().reset_index()[['varname', 'varcode']]\n",
    "print unique_species.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~Aim is to construct a list of dicts with keys `pattern` and `lct`. Intended to mean: if _this_ pattern is found in a species name, map it to _this_ land cover type. ~~\n",
    "\n",
    "Can't map individual species to individual land cover type. E.g. pine exists in both pine and transition forest. How to attribute \n",
    "\n",
    "how to distinguish a small area of pine forest's contribution from a large area of transition forest? They might generate similar amounts of pollen, but result from very different landscapes.\n",
    "\n",
    "Maybe I need to further simplify the land cover types I'd like to represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map land land cover types to species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Landcover types which are represented in my model are as follows:\n",
    "\n",
    "##### 1. Water/ Quarry\n",
    "No pollen produced\n",
    "\n",
    "##### 2. Burnt\n",
    "No pollen produced\n",
    "\n",
    "#### 3. Barley \n",
    "Grass pollen produced, belongs to the Poaceae (formerly known as Gramineae) family.\n",
    "\n",
    "None present at the start of a simulation\n",
    "\n",
    "#### 4. Wheat \n",
    "Grass pollen produced, belongs to the Poaceae (formerly known as Gramineae) family\n",
    "\n",
    "None present at the start of a simulation\n",
    "\n",
    "#### 5. Depleated Agricultural Land\n",
    "No pollen produced\n",
    "\n",
    "None present at the start of a simulation\n",
    "\n",
    "#### 6. Shrubland\n",
    "- Grasses (Poaceae, formerly Gramineae, family)\n",
    "- Juniper (Genus:\tJuniperus, belongs to cypress family Cupressaceae)\n",
    "\n",
    "#### 7. Pine forest\n",
    "Anything belonging to the pinus genera\n",
    "\n",
    "#### 9. Deciduous forest\n",
    "- Beech family, Fagaceae\n",
    "- Chestnut (Castanea genus)\n",
    "\n",
    "#### 10. Oak forest\n",
    "- Anything in quercus\n",
    "\n",
    "##### Comment on Transition Forest\n",
    "- Originally in model\n",
    "- No way to distinguish from pollen between pine forest, oak forest and transition forest. As it stands, it makes sense to integrate out the transition forest state, so we create the possibility of transitioning directly between pine and oak, subject to the kind of environmental conditions which would support transition forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_lct_maps = {    \n",
    "    # SHRUBLAND\n",
    "    # grasses\n",
    "    r'(.*(?i)Poaceae.*|.*(?i)Gramineae.*|.*(?i)Cerealia.*)' : 'shrubland',\n",
    "    # juniper\n",
    "    r'.*(?i)Juniperus.*' : 'shrubland',\n",
    "    # and cypress family\n",
    "    r'.*(?i)Cupressaceae.*' : 'shrubland',\n",
    "    # quillwort (prolific in Sanabria Marsh)\n",
    "    r'.*(?i)Isoetes.*' : 'shrubland',\n",
    "    # Goosefoot family (prolific in e.g. San Rafael)\n",
    "    r'.*(?i)Chenopodiaceae.*' : 'shrubland',\n",
    "    # Mugwort genus (prolific in e.g. San Rafael)\n",
    "    r'.*(?i)Artemisia.*' : 'shrubland',\n",
    "    # flowering plants in the same family as lettuce, dendelions etc\n",
    "    r'.*(?i)Cichorioideae.*' : 'shrubland',\n",
    "    # family of shrubby plants\n",
    "    r'.*(?i)Asteroideae.*' : 'shrubland',    \n",
    "    # sedge family (superficially resemble grasses)\n",
    "    r'.*(?i)Cyperaceae.*' : 'shrubland', # see e.g. Atxuri    \n",
    "    # heather\n",
    "    r'.*(?i)Calluna vulgaris.*' : 'shrubland', \n",
    "    # heather family\n",
    "    r'(.*(?i)Ericaceae.*|.*(?i)Erica-type.*|.*(?i)Erica arborea-type.*)' : 'shrubland', \n",
    "    #  celery, carrot, parsley family\n",
    "    r'.*(?i)Umbelliferae.*' : 'shrubland', \n",
    "    # celery and marthwort genus\n",
    "    r'.*(?i)Apium.*' : 'shrubland', \n",
    "    # box plant (shrubby tree)\n",
    "    r'.*(?i)Buxus.*' : 'shrubland',\n",
    "    # genus of flowering plants, buttercup genus\n",
    "    r'.*(?i)Ranunculus.*' : 'shrubland',\n",
    "    # doc/ sorrel genus\n",
    "    r'.*(?i)Rumex.*' : 'shrubland',\n",
    "     # bracken/ ferns. Associated with pine forest??\n",
    "    r'(.*(?i)Pteridium.*|.*(?i)Polypodium.*|.*(?i)Filicales.*)' : 'shrubland', \n",
    "    # genus of gymnosperm shrubs\n",
    "    r'.*(?i)Ephedra.*' : 'shrubland',    \n",
    "    # flowering plants found in wet regions\n",
    "    r'(.*(?i)Sparganium.*|.*(?i)Typha angustifolia.*)' : 'shrubland', \n",
    "    # plantain/ fleawort genus\n",
    "    r'.*(?i)Plantago.*' : 'shrubland',\n",
    "    # olive genus\n",
    "    r'.*(?i)Olea.*' : 'shrubland',\n",
    "    \n",
    "    # PINE FOREST\n",
    "    r'\\s*(?i)Pinus\\s*' : 'pine_forest',\n",
    "    \n",
    "    # DECIDUOUS FOREST\n",
    "    # chestnut\n",
    "    r'.*(?i)Castanea.*' : 'deciduous_forest',\n",
    "    # birch\n",
    "    r'.*(?i)Betula.*' : 'deciduous_forest',\n",
    "    # Beech family\n",
    "    r'.*(?i)Fagaceae.*' : 'deciduous_forest',\n",
    "    # Beech genus\n",
    "    r'.*(?i)Fagus.*' : 'deciduous_forest',\n",
    "    # Alder genus\n",
    "    r'.*(?i)Alnus.*' : 'deciduous_forest',\n",
    "    # Hazel\n",
    "    r'.*(?i)Corylus.*' : 'deciduous_forest',\n",
    "    # Willow\n",
    "    r'.*(?i)Salix.*' : 'deciduous_forest',  \n",
    "    # Hornbeam\n",
    "    r'.*(?i)Carpinus.*' : 'deciduous_forest',  \n",
    "    \n",
    "    # OAK FOREST\n",
    "    r'.*(?i)Quercus.*' : 'oak_forest'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function which, given a species name, returns a list of land cover types. h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lct(species_name, pol_lct_dict, verbose=False):\n",
    "    \"\"\"Given a species name, map it to a land cover type.\n",
    "    \n",
    "    Throw a ValueError if species name matches more than one land cover type.\n",
    "    \"\"\"\n",
    "    lcts = []\n",
    "    for r in pol_lct_dict.keys():\n",
    "        if re.match(r, species_name):\n",
    "            lcts.append(pol_lct_dict[r])\n",
    "            if verbose:\n",
    "                print r + ' matches ' + species_name\n",
    "    \n",
    "    if len(lcts) > 1:\n",
    "        # len(lcts)\n",
    "        raise ValueError('Species name {0} matched multiple land cover type '\\\n",
    "                        'regex strings: {1}'.format(species_name, lcts))\n",
    "    elif len(lcts) == 0:\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        return lcts[0]\n",
    "\n",
    "print get_lct('Carpinus', pol_lct_maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply `get_lct` to each species included in the chronology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_species['lct'] = unique_species.varname.apply(lambda x: get_lct(x, pol_lct_maps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_species = unique_species[unique_species.lct.notnull()]\n",
    "mapped_species.to_csv('species_to_landcover_mapping.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate proportion of pollen, for each study site, accounted for by land-cover type map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each study site, find the overall percentage of pollen contributed by each species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pollen_by_site_species = chrons.groupby([chrons.index.get_level_values(0), 'varcode']).sum().reset_index(1)\n",
    "all_pollen_by_site = all_pollen_by_site_species.groupby(level=0).sum().rename(columns={'pcount':'site_total'})\n",
    "all_pollen_by_site_species = all_pollen_by_site_species.join(all_pollen_by_site)\n",
    "all_pollen_by_site = None # remove temporary dataframe used in join\n",
    "all_pollen_by_site_species['species_pct'] = all_pollen_by_site_species.pcount/all_pollen_by_site_species.site_total*100\n",
    "all_pollen_by_site_species = all_pollen_by_site_species.drop(['pcount', 'site_total'], axis=1).reset_index()\n",
    "print all_pollen_by_site_species.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add `varname` and `lct` coulmns from `unique_species`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge in species info\n",
    "all_pollen_by_site_species = all_pollen_by_site_species.merge(unique_species, on='varcode', how='left')\n",
    "# sort by site and percent pollen contributed by species\n",
    "all_pollen_by_site_species = all_pollen_by_site_species.sort_values(by=['sitecode','species_pct'], ascending=False).set_index('sitecode')\n",
    "# replace None with the string 'not_specified' in the joined in lct column\n",
    "all_pollen_by_site_species.lct = all_pollen_by_site_species.lct.fillna('not_specified')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print all_pollen_by_site_species.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_accounted_by_lct = all_pollen_by_site_species.reset_index().groupby(['sitecode', 'lct']).sum()\n",
    "pol_accounted_by_lct = pol_accounted_by_lct.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_accounted_by_lct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "pol_accounted_by_lct.plot(kind='bar', stacked=True, ax=ax)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unexplained_pollen = all_pollen_by_site_species[all_pollen_by_site_species.lct=='not_specified']\n",
    "for i in unexplained_pollen.index.unique():\n",
    "    print unexplained_pollen.loc[i].drop('lct', axis=1).head()\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proportions of pollen not falling into one of the groups represented in the model above is deeped acceptable, i.e. at least 90% of pollen for simulated study sites is attributed to a modelled land cover type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REPLACE Consider only most abundant species overall across study sites\n",
    "- At this point, each species in a list of the identified species with the most pollen accross all sites is matched manually to one of grass, seeder, sprouter, shrub or exclude in an external csv file. \n",
    "- This is sub-optimal as the files are edited manually, making it difficult for someone else to track the logic -- we should exploit the readability of Python to make this explicit.\n",
    "- Instead, propose to use a series of regular expressions to create a map between species and plant functional type\n",
    "- Target should be to get at least 90% of pollen for each site accounted for in one of the landcover types I propose as part of my model. \n",
    "- Since the grouping of species into different functional types effectievly defines a model, it should be set up so a list of regular expressions conditions can be passed to a function to apply them and return the resulting dataframe in the expected format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_species(n):\n",
    "    #return a dataframe giving top n species \n",
    "    # for all cores in chrons   \n",
    "    res = pd.DataFrame(columns=['var_', 'varname', 'count', 'sitename'])\n",
    "    for ssite in chrons.sitename.unique():\n",
    "        df = chrons[chrons.sitename==ssite]\n",
    "        df = df.groupby(['var_', 'varname']).agg({'count' : 'sum'}).reset_index()\n",
    "        df['sitename'] = ssite\n",
    "        df = df.sort_values(by='count', ascending=False).head(n)\n",
    "        res = res.append(df)\n",
    "        res = res.reset_index(drop=True)\n",
    "        res.var_ = res.var_.astype('int')\n",
    "        res = res[['sitename', 'var_', 'varname', 'count']]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_species = get_top_species(10)\n",
    "top_species = top_species.groupby(['var_', 'varname']).agg({'sitename' : 'count'})\n",
    "top_species = top_species.sort_values('sitename', ascending=False)\n",
    "top_species.columns = ['sitecount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print top_species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add to this list any variables which are some form of pinus which have not already been identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinus_species = chrons[chrons.varname.str.lower().str.contains('pinus')][['var_', 'varname']].drop_duplicates()\n",
    "print pinus_species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the Carpinus types (these are actually in the Birch family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinus_species = pinus_species.drop([438, 8], axis=0).set_index('var_')\n",
    "print pinus_species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find pinus species not already listed in `top_species`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinus_species = pinus_species.join(top_species.reset_index(1)['sitecount'], how='left')\n",
    "pinus_species = pinus_species[pinus_species.sitecount.isnull()].fillna(0)\n",
    "pinus_species = pinus_species.reset_index().set_index(['var_','varname'])\n",
    "print pinus_species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append to `top_species`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_species = top_species.append(pinus_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_species.to_csv('top_species.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### REPLACE Edit list of species manually outside of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_species = pd.read_csv('top_species_edited.csv',\n",
    "                         index_col='var_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Prepare top species for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_species[(top_species.group<>'exclude') & (top_species.group.notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chrons = chrons.join(top_species['group'], on='var_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chrons.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Get total pollen contributed by each group for each entity and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "group_counts = chrons.groupby(['e_', 'sample_', 'group']).agg({'count' : 'sum'})\n",
    "chrons = chrons.join(group_counts, on=['e_', 'sample_', 'group'], rsuffix='_group_tot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "group_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create a new dataframe, `top_chrons` to store only those rows from `chrons` where the entry corresponds to one of hte groups considered (shrub, sprouter, grass and seeder). First find unique combinations of values relevant for specifying pollen counts at the group level. This means dropping columns used for identifying species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_chrons = chrons.drop(['var_', 'count', 'varcode', 'varname', 'pollen_pct'], axis=1)\n",
    "top_chrons = chrons[['e_', 'sample_', 'agebp', 'site_', 'sitename', 'count_sample_tot', 'group']].drop_duplicates()\n",
    "top_chrons.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Remove rows corresponding to excluded or unspecified groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_chrons = top_chrons[(top_chrons.group<>'exclude') & (top_chrons.group.notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_chrons.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Join in total pollen counts by group from `group_counts` data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_chrons = top_chrons.join(group_counts, on=['e_', 'sample_', 'group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_chrons['group_pct'] = top_chrons['count']/top_chrons.count_sample_tot*100\n",
    "top_chrons.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_chrons.columns = ['e_', 'sample_', 'agebp', 'site_', 'sitename', 'count_sample_tot',\n",
    "                      'group', 'count_group_tot', 'group_pct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_chrons.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Finally pivot dataframe to provide easier access to data for plotting and statistical analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pol_df = top_chrons.drop(['e_', 'sample_', 'site_', 'count_sample_tot'], axis=1)\n",
    "pol_df.columns = ['agebp', 'sitename', 'group', 'group_count', 'group_pct']\n",
    "pol_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pol_df = pol_df.set_index(['sitename', 'agebp', 'group'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Charco da Candieira contains multiple entries for three samples. At time of writing (4 days before upgrade report is due) I simply don't have time to debug this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pol_df[pol_df.index.duplicated(False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For now I'll do a quick and dirty exclusion of all but the first of each of these entries, but will need to address more carefully as a TODO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pol_df = pol_df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pol_df = pol_df[~pol_df.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pol_df[pol_df.index.duplicated(False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pol_df = pol_df.unstack()\n",
    "pol_df = pol_df.fillna(0)\n",
    "pol_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pol_df.to_pickle('pol_df.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Plot pollen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    pol_df\n",
    "except NameError:\n",
    "    pol_df = pd.read_pickle('pol_df.pickle')\n",
    "    print 'pol_df read from file.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### For print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_print_chronology(sitename, earliest, latest, figlabel=None, save=False):\n",
    "    df = pol_df.loc[sitename, :]['group_pct'] #extract pollen percents for specified site\n",
    "    df = df[(df.index <= earliest) & (df.index >= latest)] # exclude samples from earlier that specified years before present\n",
    "    \n",
    "    def tweak_pct_ticks(axis, pct_vals):\n",
    "        max_pct = int(round(pct_vals.max()*1.1))\n",
    "        \n",
    "        def get_increments(maximum):\n",
    "            while maximum%4 <> 0:\n",
    "                maximum += 1\n",
    "            return [maximum/4 * i for i in range(5)]\n",
    "        \n",
    "        increments = get_increments(max_pct)\n",
    "        axis.set_xlim(0, increments.pop())\n",
    "        axis.xaxis.set_ticks(increments)\n",
    "        \n",
    "    def make_under_line_polygon(xx, yy, e, l):\n",
    "        line_vertices = np.column_stack((xx, yy))\n",
    "        leftmost_corners = np.array([[0, e], [0,l]])\n",
    "        vertices = np.concatenate((line_vertices, leftmost_corners))\n",
    "        return Polygon(vertices, True)       \n",
    "    \n",
    "    pollen_line_colour = '#145D85'\n",
    "    \n",
    "    f, axes = plt.subplots(1, len(df.columns), sharey=True)\n",
    "    for i, group in enumerate(df.columns):\n",
    "        xx = df[group].values\n",
    "        yy = df.index.values\n",
    "        axes[i].plot(xx,yy, color=pollen_line_colour)\n",
    "        axes[i].set_title(group.title())\n",
    "        axes[i].set_ylim([latest, earliest])\n",
    "        tweak_pct_ticks(axes[i], xx)\n",
    "        \n",
    "        poly = make_under_line_polygon(xx, yy, earliest, latest)\n",
    "        p = PatchCollection([poly], alpha=0.4)\n",
    "        p.set_color(pollen_line_colour)\n",
    "        axes[i].add_collection(p)\n",
    "        \n",
    "        if i == 0:\n",
    "            axes[i].set_ylabel('yrs BP', fontsize=13)\n",
    "            if figlabel:\n",
    "                xticks = axes[i].get_xticks()\n",
    "                yticks = axes[i].get_yticks()\n",
    "                xtick_scale = xticks[1]-xticks[0]\n",
    "                ytick_scale = yticks[1]-yticks[0]\n",
    "\n",
    "                axes[i].text(-1.15*xtick_scale, latest-0.5*ytick_scale, \n",
    "                             figlabel,\n",
    "                             fontdict = {'weight': 'bold',\n",
    "                                         'size': 16}\n",
    "                            )\n",
    "    \n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.subplots_adjust(hspace=0, wspace=0)\n",
    "    f.text(0.51, 0.02, '% contribution to total pollen sample', ha='center', fontsize=13)\n",
    "    #plt.suptitle(sitename, y=1.05, fontsize=12)\n",
    "    \n",
    "    if save:\n",
    "        d = os.path.join('plots')\n",
    "        if not os.path.exists(d):\n",
    "            os.makedirs(d)\n",
    "\n",
    "        plt.savefig(os.path.join('plots',\n",
    "                                 (sitename.replace(' ', '_')+'_'\n",
    "                                 +str(earliest)+'-'+str(latest)+'.pdf')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for s in pol_df.index.get_level_values(0).unique():\n",
    "    print s\n",
    "    plot_print_chronology(s, 15000, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Of these, to my eye, San Rafael looks the most interesting (like there's a lot going on). \n",
    "\n",
    "On the other hand, what's going on in Navarres at 6000 years ago with sprouters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from bokeh.io import push_notebook, show, output_notebook\n",
    "from bokeh.layouts import gridplot, widgetbox, column# container for bokeh figure objects\n",
    "from bokeh.models.widgets import Dropdown\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.plotting import figure\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_interactive_chronology(sitename):\n",
    "    df = pol_df.loc[sitename, :]['group_pct'] #extract pollen percents for specified site\n",
    "    \n",
    "    # create a column data source for the plots to share\n",
    "    source = ColumnDataSource(data=df.reset_index().to_dict('list'))\n",
    "    \n",
    "    # container for bokeh figure objects\n",
    "    plots = [] \n",
    "    time_range=None\n",
    "    \n",
    "    TOOLS = \"ypan,ywheel_zoom\"\n",
    "    \n",
    "    def get_width(base, factor, plot_num):\n",
    "        # function to increase width of first plot, since this ends up narrowed\n",
    "        # due to being the only one with yaxis labels.\n",
    "        if plot_num > 0:\n",
    "            return base\n",
    "        else:\n",
    "            return int(round(base*(1+factor)))\n",
    "    \n",
    "    for i, group in enumerate(df.columns):\n",
    "        p = figure(tools=TOOLS, plot_width=get_width(150, .25, i), \n",
    "                   plot_height=500, y_range=time_range,\n",
    "                   title=group.title())\n",
    "        p.line(group, 'agebp', source=source)\n",
    "        if i == 0:\n",
    "            p.y_range.flipped = True\n",
    "            time_range = p.y_range\n",
    "        else:\n",
    "            p.yaxis.major_label_text_font_size = '0pt'\n",
    "                    \n",
    "        plots.append(p)\n",
    "   \n",
    "    p = gridplot([plots])\n",
    "    t = show(p, notebook_handle=True)\n",
    "                \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for s in pol_df.index.get_level_values(0).unique():\n",
    "    print s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pol_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loc[u'Charco da Candieira', :]['count_group_tot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Earliest date for Charco da Candieira:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def print_daterange(sitename):\n",
    "    df = pol_df.loc[sitename, :]['group_count']\n",
    "    latest = df.index.min()\n",
    "    earliest = df.index.max()\n",
    "    print 'earliest date: {0} yr BP'.format(earliest)\n",
    "    print 'latest date: {0} yr BP'.format(latest)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for s in pol_df.index.get_level_values(0).unique():\n",
    "    print s\n",
    "    print_daterange(s)\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_interactive_chronology(u'Algendar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pol_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Points of particular interest in time series (discussed in upgrade report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### San Rafael 4000 - 8000 yrs BP\n",
    "Big variation in grasses shrubs and sprouters around the time it is thought agriculture reached Iberia (6500 yrs BP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_print_chronology(u'San Rafael', 8500, 1000, figlabel='A', save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Navarres 6000 - 7000 yrs BP\n",
    "~ 200 year oscillation in percentages of grass and seeders 6400 - 6800 yrs BP, followed by sudden and sustained increase in sprouters after 6400 yrs BP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_print_chronology(u'Navarr√©s', 10500, 3000, figlabel='B', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 4. Apply the LRA to infer land-cover proportion from pollen abundance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. TODO Output plant functional group time-series for each study site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEMP Time-series of proportion of total pollen abundance for each plant functional group\n",
    "- NOTE at present (May 18) I've not implemented the LRA yet so will output pollen _abundance_ between species, rather than using the LRA's method of correcting for the variance in pollen produced by different species.\n",
    "- This is to get a preliminary model off the ground and should be corrected for as a priority."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pollen chronologies for study sites, and mappings to land cover classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'chrons' not in locals():\n",
    "    import matplotlib \n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    # made in section 2 above\n",
    "    chrons = pd.read_pickle('chrons.pkl')\n",
    "    \n",
    "if 'mapped_species' not in locals():\n",
    "    # made in section 3 above\n",
    "    mapped_species = pd.read_csv('species_to_landcover_mapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print chrons.head()\n",
    "print chrons[chrons.pcount>2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note the very high counts for san_rafael. Are these realistic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print chrons.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrons = chrons.reset_index().merge(mapped_species.drop('varname', axis=1), on='varcode', how='left')\n",
    "chrons = chrons.dropna()\n",
    "print chrons.shape\n",
    "print chrons.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollen_abundance = chrons.groupby(['sitecode', 'e_', 'agebp', 'lct']).sum().unstack(3)\n",
    "pollen_abundance = pollen_abundance.fillna(0)\n",
    "pollen_abundance.loc[:,('pcount', 'total')] = pollen_abundance.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollen_abundance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert abundance to proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in pollen_abundance.pcount.columns:\n",
    "    if c <> 'total':\n",
    "        pollen_abundance.loc[:,('pprop', c)] = pollen_abundance.loc[:, ('pcount', c)]/pollen_abundance.loc[:, ('pcount', 'total')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollen_abundance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a quick look at the data to check it seems reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "pollen_abundance.loc[('navarres',  471), 'pprop'].plot(ax=ax)\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write processed pollen proportion data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollen_abundance.to_pickle('pollen_timeseries.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the above are pollen _proportion_ time series. These can be used as proportions feeding into an NLM. See the `/home/andrew/Dropbox/codes/python/notebooks/modified_random_clusters/implement_modified_random_clusters.html` for details\n",
    "\n",
    "#### TO move across to MRC notebook\n",
    "notebook for details of Supposing I start simulating Navarres from 7000 yrs BP, that gives me the following starting proportions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to find the nearest value to a given value in a numpy array\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav_dat = pollen_abundance.loc[('navarres',  471), 'pprop']\n",
    "nav_initial = nav_dat.loc[find_nearest(nav_dat.index.values, 7000)]\n",
    "print nav_initial\n",
    "#print find_nearest(nav_dat.index.values, 7000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jan 2019 -- Add time derivatives to timeseries dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollen_abundance = pd.read_pickle('pollen_timeseries.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollen_abundance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollen_abundance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollen_abundance['pprop'].xs('albufera_alcudia', level='sitecode').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to work out how to calculate, for each core, the pollen proportion slope with respect to the agebp index. This can be gathered as a new dataframe with the same MultiIndex as `pollen_abundance['pprop']`. This can then be joined back into `pollen_abundance` as `pollen_abundance['pprop_prime']`. The gradient of this will give `pollen_abundance['pprop_prime_prime']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pollen_abundance.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Rough working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Correlations between variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's look at how the counts of different groups correlate with each other within each study site through time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_chrons.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['group_pct']['grass'].loc['Sanabria Marsh'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df.loc[u'Navarr√©s''Sanabria Marsh', :]['count_group_tot'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Are there clusters we can find in the counts of different pollen? Could investigate using KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pollen_conts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pollen_conts['pollen_pct']['mean'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nav_pine = nav_dat[nav_dat.varname=='Pinus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nav_pine['count'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nav_pine['pollen_pct'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nav_dat[nav_dat.varname=='Concentration spikes'].pollen_pct.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### TODO General theory to look up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Looking at understanding pollen spikes\n",
    "https://quantpalaeo.wordpress.com/2017/07/28/pollen-spikes/\n",
    "\n",
    "Calculating deposition rates\n",
    "http://www.europeanpollendatabase.net/wiki/lib/exe/fetch.php?media=epd_age-depth.pdf\n",
    "\n",
    "Using litholgy (depth) and and c14 (time) or (equivalently??) `depthcm` and `age` columns from `agebasis` table could be used to calculate sediment deposition rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "epd.ssites.append(762)\n",
    "epd.ssites.append(1260)\n",
    "epd.ssites.append(76)\n",
    "epd.ssites.append(560)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "epd.ssites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
