{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstructing the land-cover of prehistoric landscapes\n",
    "\n",
    "The purpose of this notebook is to :\n",
    "1. Load pollen abundance time-series data extracted from the European Pollen Database for a selection of sites I am studying in the development of my PhD thesis.\n",
    "2. Explore, consider the limitations of, and clean that data.\n",
    "3. Support the systematic assignment of pollen types identified in the empirical data to the categorical land-cover types which will be represented in my simulation models. This is a form of modelling in itself, and serves as an abstraction couched in terms of the notion of a plant functional type. That is, plant _species_ which are postulated to be functionally identical as far as the model is concerned are assigned to the same plant functional group. This will be achieved using regular expressions to embelish the data in a pandas dataframe.\n",
    "4. Apply the Landscape Reconstruction Algorithm (LRA) to the pollen abundance data to infer the _proportion_ of landscape occupied from each plant functional group.\n",
    "5. Produce, for each of my empirical study sites, time-series of the proportion of landscape occupied for each of the functional groups represented in the model for the duration of time for which there is abundance data for each study site. This will be presented in the form of a `.csv` file and a plot for each study site. \n",
    "\n",
    "The only input required to run this notebook is a path to the file `site_pollen_abundance_ts.csv` which is output from [`epd-query`](https://github.com/lanecodes/epd-query)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "from typing import Dict, List\n",
    "\n",
    "import unidecode\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "mpl.rcParams['font.family'] = 'CMU Sans Serif'\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#import seaborn as sns\n",
    "from ipywidgets import interact, fixed\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMP_DIR = Path('../tmp')\n",
    "OUTPUT_DIR = Path('../outputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load pollen data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data = pd.read_csv(TMP_DIR / 'site_pollen_abundance_ts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data.groupby(['sitename', 'e_']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore, condider the limitations of, and clean pollen core data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check numbers of samples in each core, narrow core selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data for one of the three Navarres cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav_dat = epd_data[epd_data['e_'] == 469]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav_dat.sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that much of the pollen recorded in the database for this sediment core corresponds to [pollen spike](https://quantpalaeo.wordpress.com/2017/07/28/pollen-spikes/), with `varcode` values of `conc.spk`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav_dat['sample_'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More troublingly, navares core 469, NAVA1 has only 15 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav2 = epd_data[epd_data['e_'] == 470]\n",
    "nav2['sample_'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav3 =  epd_data[epd_data['e_'] == 471]\n",
    "nav3['sample_'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going forward, I'll prefer NAVA3 over NAVA1 and NAVA2 since it contains more samples. If I find something which makes NAVA3 seem unreliable, I may reconsider. For now, drop NAVA1 and NAVA2 from the `epd_data` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data = epd_data[~epd_data['e_'].isin([469, 470])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at top ten pollen contributing species for each study site, remove sediment spike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_species(epd_data):\n",
    "    for ssite in epd_data['sitename'].unique():\n",
    "        print('\\n'+ssite)\n",
    "        df = epd_data[epd_data['sitename']==ssite]\n",
    "        df = df.groupby(['var_', 'varcode', 'varname']).agg({'count' : 'sum'})\n",
    "        print(df.sort_values(by='count', ascending=False).head(5))\n",
    "    del df\n",
    "\n",
    "print_top_species(epd_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navarres alone seems to have a lot of pollen spike in it. Also Monte Areo mire and Charco da Candieira have Lycopodium spike added. See [here](https://palynology.wordpress.com/2012/10/07/pollen-spike/) for background on pollen spike. To keep analyses between sites consistent, I will exclude these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_varcodes(df: pd.DataFrame, varcodes: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"Remove rows corresponding to specified varcodes from epd DF.\"\"\"\n",
    "    return df[~df['varcode'].isin(varcodes)]\n",
    "\n",
    "\n",
    "def remove_varcodes_test_df():\n",
    "    return pd.DataFrame({\n",
    "        'varcode': ['goodvar1', 'badvar1', 'badvar2', 'goodvar2'],\n",
    "        'count': np.random.randint(0, 4000, size=4)\n",
    "    })\n",
    "\n",
    "\n",
    "def test_remove_varcodes(test_df):\n",
    "    res_df = remove_varcodes(test_df, ['badvar1', 'badvar2'])\n",
    "    assert res_df.iloc[0]['varcode'] == 'goodvar1'\n",
    "    assert res_df.iloc[1]['varcode'] == 'goodvar2'\n",
    "    assert len(res_df.index) == 2\n",
    "    \n",
    "test_remove_varcodes(remove_varcodes_test_df())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_pollen_spike = True\n",
    "if exclude_pollen_spike:\n",
    "    epd_data = remove_varcodes(\n",
    "        epd_data, ['Spi/tab', 'Lyc(ad)', 'Lyc(ct)', 'Lyc']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also note that San Rafael has a significant proportion of Botryococcus in its samples. This is a type of green algae. Since this doesn't correspond to any _land_ plant species, we exclude it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aquatic_plant_codes = [\n",
    "    'Bry',\n",
    "    'Zyg-T',\n",
    "    'Spr-T',\n",
    "    'Pot',      # Potamogeton, aquatic plant\n",
    "    'Clo.i-T',  # Closterium idiosporum, green algae\n",
    "    'Spi.cf.s', # Spirogyra cf. scrobiculata, green algae\n",
    "    'Trl.s',    # Trilete spore(s),  not from modern terrestrial plant\n",
    "]\n",
    "\n",
    "exclude_non_land_plants = True\n",
    "if exclude_non_land_plants:\n",
    "    epd_data = remove_varcodes(epd_data, aquatic_plant_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identified lots of moss (Sphagnum) in, e.g. Atxuri. Exclude this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_mosses = True\n",
    "if exclude_mosses:\n",
    "    epd_data = remove_varcodes(epd_data, ['Sph'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungal spores such as Glomus turn up in Navarres. Exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fungal_species_codes = [\n",
    "    'Glomus',\n",
    "    'Pos',  # Polyadosporites, fungal spore http://www.redalyc.org/html/454/45437346003/index.html\n",
    "]\n",
    "\n",
    "exclude_fungi = True\n",
    "if exclude_fungi:\n",
    "    epd_data = remove_varcodes(epd_data, fungal_species_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove records corresponding to pollen which could not be identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrecognised_species_codes = [\n",
    "    'Ind.unkn',  # found in navarres\n",
    "    'T16C',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_unrecognised = True\n",
    "if exclude_unrecognised:\n",
    "    epd_data = remove_varcodes(epd_data, unrecognised_species_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, `epd_data` contains entries for all:\n",
    "1. sediment cores\n",
    "2. samples (depths/ ages)\n",
    "3. species (careful to exclude pollen spike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Give each site an easily typed `sitecode` to refer to as an index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be convenient to be able to refer to sites as an index. To make these easy to type, create a `sitecode` column which strips out spaces and removes any unicode names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epd_data['sitename'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data['sitecode'] = (\n",
    "    epd_data['sitename']\n",
    "    .apply(unidecode.unidecode)\n",
    "    .str.replace(' ', '_')\n",
    "    .str.lower()\n",
    ")\n",
    "\n",
    "print(epd_data.sitecode.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I plan to use `sitename` as an index going forward because it's natural to think in terms of study sites. This means I don't need other information in the dataframe I take forward in my analyses at the study site level of detail. So this information can easily be rerieved if needs be when debugging, I save this to disk and remove the extra columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_meta_fields = ['sitecode', 'sitename', 'site_', 'sigle', 'e_', 'chron_']\n",
    "site_meta = epd_data.groupby(site_meta_fields).size().rename('num_records')\n",
    "site_meta.to_csv(TMP_DIR / 'site_metadata.csv', encoding='utf8', header=True)\n",
    "epd_data = epd_data.drop(\n",
    "    [x for x in site_meta_fields if x != 'sitecode'], axis=1\n",
    ")\n",
    "epd_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sample_` (a database key from the EPD) is also redundant at this point, since we can idenify each sample from its `agebp`. Similarly each variable (pollen species) is uniquely identified by its `varcode` so we can also drop `var_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data = epd_data.drop(['sample_', 'var_'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check `agebp` and `count` can be converted to `int` without loss of data, and do the conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_field_to_int(df: pd.DataFrame, field: str) -> pd.DataFrame:\n",
    "    \"\"\"Convert named float field to int if no data would be lost.\"\"\"\n",
    "    assert (~df[field].isna()).all(), f'missing data found in {field}'\n",
    "    assert ((df[field] - df[field].astype(int)) == 0).all(), (\n",
    "     f'casting {field} to int caused loss of data'\n",
    "    )\n",
    "    df[field] = df[field].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data = (\n",
    "    epd_data\n",
    "    .pipe(lambda df: convert_field_to_int(df, 'agebp'))\n",
    "    .pipe(lambda df: convert_field_to_int(df, 'count'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a unique index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data = epd_data.set_index(['sitecode', 'agebp', 'varcode']).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find index is unexpectedly not unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check which sites duplicates are coming from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data[epd_data.index.duplicated()].groupby(level=['sitecode']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_affected = 107 / len(epd_data.loc['charco_da_candieira'].index) * 100\n",
    "print(f'{round(pct_affected, 2):.2f}% of charco_da_candieira entries are duplicates')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As less than 1% of Charco da Candieira sample/ species combinations are affected, we will simply assume that where multiple entries are associated for a species in a single sample, the correct count is obtained by summing any duplicates. No other site's data are affected by this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_index_len = len(epd_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varcode_to_varname_df = (\n",
    "    epd_data.reset_index(level='varcode')[['varcode', 'varname']]\n",
    "    .drop_duplicates()\n",
    "    .set_index('varcode')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data = (\n",
    "    epd_data['count']\n",
    "    .groupby(level=['sitecode', 'agebp', 'varcode']).sum()\n",
    "    .to_frame()\n",
    "    .join(varcode_to_varname_df)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert initial_index_len - len(epd_data.index) == 107\n",
    "assert epd_data.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename `count` to avoid an understandable but irritating namespace collision with the `pd.Series.count` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data = epd_data.rename(columns={'count': 'pcount'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data.loc['navarres'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data.groupby(level=['sitecode', 'agebp']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`epd_data` is now prepped and ready to use for subsequent analyses. Serialise a csv file so it can be retrieved without rerunning the above cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data.to_csv(TMP_DIR / 'clean_epd_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TODO Relate identified pollen species with model-dependent plant functional types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    epd_data\n",
    "except NameError:\n",
    "    epd_data = (\n",
    "        pd.read_csv(TMP_DIR / 'clean_epd_data.csv')\n",
    "        .set_index(['sitecode', 'agebp', 'varcode'])\n",
    "    )   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve a list of unique `varname`-s found amongst the sediment cores analysed thus far in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_species = (\n",
    "    epd_data.reset_index()[['varname', 'varcode']].drop_duplicates()\n",
    "    .set_index('varcode')\n",
    ")\n",
    "unique_species.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the most common species for each study site\n",
    "\n",
    "The objective is to ensure that approximately 90% of counted pollen is assigned to one of the following land cover type groups:\n",
    "\n",
    "- Shrubland: includes grasses (Poaceae, formerly Gramineae, family), and juniper (genus Juniperus, belongs to cypress family Cupressaceae).\n",
    "- Pine forest: anything belonging to the Pinus genus\n",
    "- Deciduous forest: Beech family, Fagaceae and Chestnut (Castanea genus)\n",
    "- Oak forest: anything belonging to the Quercus genus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find percentage of each study site's total contributed by each species. These are the species whose mapping to land cover types are most important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    epd_data.groupby(['sitecode', 'varcode'])['pcount'].sum().to_frame()\n",
    "    .pipe(lambda df: df.join(df.groupby('sitecode')['pcount']\n",
    "                             .sum().rename('site_total')))\n",
    "    .assign(species_pct=lambda df: df['pcount'] / df['site_total'] * 100)\n",
    "    .drop(columns='site_total')\n",
    "    .groupby('sitecode')['species_pct'].nlargest(10)\n",
    "    .reset_index(0, drop=True)\n",
    "    .to_frame()\n",
    "    .join(unique_species)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify land-cover types with pollen species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim in this section is to construct a dictionary whose keys are land cover types included in my simulation models, and whose values are regular expressions which match the names of species contributing to those land cover types. This dictionary will then be used to say: if _this_ pattern is found in a species name, map it to _this_ land cover type.\n",
    "\n",
    "The following land cover types are included in simulations, but not in the land cover type categories used in this notebook:\n",
    "\n",
    "1. Water/Quarry\n",
    "2. Burnt\n",
    "3. Depleated agricultural land\n",
    "3. Barley\n",
    "4. Wheat\n",
    "5. Transition forest\n",
    "\n",
    "Land cover types 1-3 above don't produce any pollen. Barley and wheat produce grass pollen. This belongs to the Poaceae (formerly known as Gramineae) family, and is assumed to contribute to 'Shrubland'. There is no depleated agricultural land, barley or wheat land cover present at the beginning of a simulation, as these are anthropogenically induced land cover types.\n",
    "\n",
    "I don't map pollen to the 'Transition forest' land cover type because this type is a mixture of pine and oak forest. When comparing simulation outputs to empirical pollen abundance, I will assume transition forest simulation cells contribute half a cell of pine forest pollen and half a cell of oak forest pollen. When generating Neutral Landscape models from pollen abundance, I will assume that no cells start off as transition forest, and allow transition forest cells to be introduced by a model 'burn in' period. An alternative proposal might be to change my modelling approach such that I effectively integrate out the transition forest state, so we create the possibility of transitioning directly between pine and oak, subject to the kind of environmental conditions which would support transition forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map land land cover types to species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose_regexs(regexs: List[str]) -> str:\n",
    "    \"\"\"Join list of regex patterns.\n",
    "    \n",
    "    Resulting pattern will match any one of the input patterns supplied in the\n",
    "    list.\n",
    "    \"\"\"\n",
    "    return  '|'.join(regexs)\n",
    "\n",
    "\n",
    "def test_compose_regexs():\n",
    "    test_patterns = [r'^foo.*', r'.*bar.*']\n",
    "    test_str1 = 'foo blah blah'  # match\n",
    "    test_str2 = 'blah bar foo'  # match\n",
    "    test_str3 = 'blah foo blah'  # no match\n",
    "    \n",
    "    regex = compose_regexs(test_patterns)\n",
    "    assert re.search(regex, test_str1)\n",
    "    assert re.search(regex, test_str2)\n",
    "    assert re.search(regex, test_str3) is None\n",
    "    \n",
    "test_compose_regexs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POLLEN_LCT_MAPS = {\n",
    "    'shrubland': [\n",
    "        # grasses\n",
    "        r'.*Poaceae|.*Gramineae|.*Cerealia.',\n",
    "        # juniper\n",
    "        r'.*Juniperus',\n",
    "        # and cypress family\n",
    "        r'.*Cupressaceae',\n",
    "        # quillwort (prolific in Sanabria Marsh)\n",
    "        r'.*Isoetes',\n",
    "        # Goosefoot family (prolific in e.g. San Rafael)\n",
    "        r'.*Chenopodiaceae',\n",
    "        # Mugwort genus (prolific in e.g. San Rafael)\n",
    "        r'.*Artemisia',\n",
    "        # flowering plants in the same family as lettuce, dendelions etc\n",
    "        r'.*Cichorioideae',\n",
    "        # family of shrubby plants\n",
    "        r'.*Asteroideae',\n",
    "        # sedge family (superficially resemble grasses), see e.g. Atxuri\n",
    "        r'.*Cyperaceae',\n",
    "        # heather\n",
    "        r'.*Calluna vulgaris',\n",
    "        # heather family\n",
    "        r'.*Erica(ceae|-type|\\s)',\n",
    "        #r'(.*Erica(ceae|-type|\\s)|.*Erica-type.*|.*Erica arborea-type.*)',\n",
    "        #  celery, carrot, parsley family\n",
    "        r'.*Umbelliferae',\n",
    "        # celery and marthwort genus\n",
    "        r'.*Apium',\n",
    "        # box plant (shrubby tree)\n",
    "        r'.*Buxus',\n",
    "        # genus of flowering plants, buttercup genus\n",
    "        r'.*Ranunculus',\n",
    "        # doc/ sorrel genus\n",
    "        r'.*Rumex',\n",
    "         # bracken/ ferns. Associated with pine forest??\n",
    "        r'.*Pteridium|.*Polypodium|.*Filicales',\n",
    "        # genus of gymnosperm shrubs\n",
    "        r'.*Ephedra',\n",
    "        # flowering plants found in wet regions\n",
    "        r'.*Sparganium|.*Typha angustifolia',\n",
    "        # plantain/ fleawort genus\n",
    "        r'.*Plantago',\n",
    "        # olive genus\n",
    "        r'.*Olea',\n",
    "    ],\n",
    "    'pine_forest': [\n",
    "        # PINE FOREST\n",
    "        r'\\s?Pinus\\s?',\n",
    "    ],\n",
    "    'deciduous_forest': [\n",
    "        # Chestnut\n",
    "        r'.*Castanea',\n",
    "        # Birch\n",
    "        r'.*Betula',\n",
    "        # Beech family\n",
    "        r'.*Fagaceae',\n",
    "        # Beech genus\n",
    "        r'.*Fagus',\n",
    "        # Alder genus\n",
    "        r'.*Alnus',\n",
    "        # Hazel\n",
    "        r'.*Corylus',\n",
    "        # Willow\n",
    "        r'.*Salix',\n",
    "        # Hornbeam\n",
    "        r'.*Carpinus',\n",
    "    ],\n",
    "    'oak_forest': [\n",
    "        # OAK FOREST\n",
    "        r'\\s?Quercus\\s?',\n",
    "    ], \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function which, given a species name, returns a list of land cover types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lct(species_name: str, pol_lct_dict: Dict[str, str],\n",
    "            verbose=False) -> str:\n",
    "    \"\"\"Given a species name, map it to a land cover type.\n",
    "    \n",
    "    Throw a ValueError if species name matches more than one land cover type.\n",
    "    \"\"\"\n",
    "    lcts = []\n",
    "    for lct_name, regex in pol_lct_dict.items():\n",
    "        if re.match(regex, species_name, re.IGNORECASE):\n",
    "            lcts.append(lct_name)\n",
    "            if verbose:\n",
    "                print(regex + ' matches ' + species_name)\n",
    "    \n",
    "    if len(lcts) > 1:\n",
    "        raise ValueError('Species name {0} matched multiple land cover type '\n",
    "                         'regex strings: {1}'.format(species_name, lcts))\n",
    "    if len(lcts) == 0:\n",
    "        return None\n",
    "\n",
    "    return lcts[0]\n",
    "\n",
    "\n",
    "def test_get_lct():\n",
    "    regex_to_lct_map = {k: compose_regexs(v) \n",
    "                        for k, v in POLLEN_LCT_MAPS.items()}\n",
    "    \n",
    "    def species_name_test(species_name, expected_lct):\n",
    "        determined_lct = get_lct(species_name, regex_to_lct_map)\n",
    "        assert  determined_lct == expected_lct, (\n",
    "            f\"expected '{expected_lct}' to be lct for species \"\n",
    "            f\"'{species_name}' but got '{determined_lct}' instead.\"\n",
    "        )\n",
    "        \n",
    "    species_name_test('Quercus ilex-type', 'oak_forest')\n",
    "    species_name_test('Quercus', 'oak_forest')\n",
    "    species_name_test('Pinus pinaster-type', 'pine_forest')\n",
    "    species_name_test('Pinus', 'pine_forest')\n",
    "    species_name_test('Rumex crispus-type', 'shrubland')\n",
    "    species_name_test('Compositae subf. Cichorioideae', 'shrubland')\n",
    "    species_name_test('Erica arborea-type', 'shrubland')\n",
    "    species_name_test('Ericaceae', 'shrubland')\n",
    "    species_name_test('Polypodium vulgare-type', 'shrubland')\n",
    "    \n",
    "test_get_lct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply `get_lct` to each species included in the chronology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_to_lct_map = {k: compose_regexs(v) \n",
    "                    for k, v in POLLEN_LCT_MAPS.items()}\n",
    "unique_species['lct'] = unique_species.varname.apply(\n",
    "    lambda x: get_lct(x, regex_to_lct_map)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_species = unique_species[unique_species['lct'].notnull()]\n",
    "mapped_species.to_csv(TMP_DIR / 'species_to_landcover_mapping.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each study site, find the percentage of pollen contributed by each species to each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data = (\n",
    "    epd_data\n",
    "    .join(epd_data\n",
    "          .groupby(level=['sitecode', 'agebp'])['pcount'].sum()\n",
    "          .rename('sample_tot'))\n",
    "    .assign(species_pct=lambda df: df['pcount'] / df['sample_tot'] * 100)\n",
    "    .drop(columns='sample_tot')\n",
    ")\n",
    "\n",
    "assert (epd_data.groupby(level=['sitecode', 'agebp'])['species_pct'].sum()\n",
    "        - 100 < 0.00001).all(), (\n",
    "    'site/ sample percentage totals should equal 100'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add `lct` to index via `unique_species`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data = (\n",
    "    epd_data\n",
    "    .join(unique_species.drop(columns='varname'))\n",
    "    .assign(lct=lambda df: df['lct'].fillna('not_specified'))\n",
    "    .set_index('lct', append=True)\n",
    "    .swaplevel(3, 2)\n",
    "    .sort_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate proportion of pollen, for each study site, accounted for by land-cover type mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate `epd_data` from species level to land cover type level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_lct_pct_df = (\n",
    "    epd_data\n",
    "    .groupby(level=['sitecode', 'lct'])['pcount'].sum()\n",
    "    .rename('lct_total_count').to_frame()\n",
    "    .pipe(lambda df: df.join(df.groupby(level='sitecode')['lct_total_count']\n",
    "                             .sum().rename('site_total')))\n",
    "    .assign(site_lct_pct=lambda df: (df['lct_total_count'] \n",
    "                                     / df['site_total'] * 100))\n",
    "    .loc[:, 'site_lct_pct']\n",
    "    .unstack()\n",
    "    .loc[:, ['shrubland', 'pine_forest', 'oak_forest', 'deciduous_forest', 'not_specified']]\n",
    ")\n",
    "\n",
    "assert (total_lct_pct_df.sum(1) - 100 < 0.00001).all(), (\n",
    "    'per-sample total lct contributions should total 100%'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_lct_pct_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "total_lct_pct_df.plot(kind='bar', stacked=True, ax=ax)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proportions of pollen not falling into one of the groups represented in the model above is deeped acceptable, i.e. at least 90% of pollen for simulated study sites is attributed to a modelled land cover type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarise `epd_data` to land cover type level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lct_data = (\n",
    "    epd_data\n",
    "    .groupby(level=['sitecode', 'agebp', 'lct'])['species_pct'].sum()\n",
    "    .unstack().replace(np.nan, 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lct_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Plot pollen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    pol_df\n",
    "except NameError:\n",
    "    pol_df = pd.read_pickle('pol_df.pickle')\n",
    "    print 'pol_df read from file.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### For print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_print_chronology(sitename, earliest, latest, figlabel=None, save=False):\n",
    "    df = pol_df.loc[sitename, :]['group_pct'] #extract pollen percents for specified site\n",
    "    df = df[(df.index <= earliest) & (df.index >= latest)] # exclude samples from earlier that specified years before present\n",
    "    \n",
    "    def tweak_pct_ticks(axis, pct_vals):\n",
    "        max_pct = int(round(pct_vals.max()*1.1))\n",
    "        \n",
    "        def get_increments(maximum):\n",
    "            while maximum%4 <> 0:\n",
    "                maximum += 1\n",
    "            return [maximum/4 * i for i in range(5)]\n",
    "        \n",
    "        increments = get_increments(max_pct)\n",
    "        axis.set_xlim(0, increments.pop())\n",
    "        axis.xaxis.set_ticks(increments)\n",
    "        \n",
    "    def make_under_line_polygon(xx, yy, e, l):\n",
    "        line_vertices = np.column_stack((xx, yy))\n",
    "        leftmost_corners = np.array([[0, e], [0,l]])\n",
    "        vertices = np.concatenate((line_vertices, leftmost_corners))\n",
    "        return Polygon(vertices, True)       \n",
    "    \n",
    "    pollen_line_colour = '#145D85'\n",
    "    \n",
    "    f, axes = plt.subplots(1, len(df.columns), sharey=True)\n",
    "    for i, group in enumerate(df.columns):\n",
    "        xx = df[group].values\n",
    "        yy = df.index.values\n",
    "        axes[i].plot(xx,yy, color=pollen_line_colour)\n",
    "        axes[i].set_title(group.title())\n",
    "        axes[i].set_ylim([latest, earliest])\n",
    "        tweak_pct_ticks(axes[i], xx)\n",
    "        \n",
    "        poly = make_under_line_polygon(xx, yy, earliest, latest)\n",
    "        p = PatchCollection([poly], alpha=0.4)\n",
    "        p.set_color(pollen_line_colour)\n",
    "        axes[i].add_collection(p)\n",
    "        \n",
    "        if i == 0:\n",
    "            axes[i].set_ylabel('yrs BP', fontsize=13)\n",
    "            if figlabel:\n",
    "                xticks = axes[i].get_xticks()\n",
    "                yticks = axes[i].get_yticks()\n",
    "                xtick_scale = xticks[1]-xticks[0]\n",
    "                ytick_scale = yticks[1]-yticks[0]\n",
    "\n",
    "                axes[i].text(-1.15*xtick_scale, latest-0.5*ytick_scale, \n",
    "                             figlabel,\n",
    "                             fontdict = {'weight': 'bold',\n",
    "                                         'size': 16}\n",
    "                            )\n",
    "    \n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.subplots_adjust(hspace=0, wspace=0)\n",
    "    f.text(0.51, 0.02, '% contribution to total pollen sample', ha='center', fontsize=13)\n",
    "    #plt.suptitle(sitename, y=1.05, fontsize=12)\n",
    "    \n",
    "    if save:\n",
    "        d = os.path.join('plots')\n",
    "        if not os.path.exists(d):\n",
    "            os.makedirs(d)\n",
    "\n",
    "        plt.savefig(os.path.join('plots',\n",
    "                                 (sitename.replace(' ', '_')+'_'\n",
    "                                 +str(earliest)+'-'+str(latest)+'.pdf')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for s in pol_df.index.get_level_values(0).unique():\n",
    "    print s\n",
    "    plot_print_chronology(s, 15000, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Of these, to my eye, San Rafael looks the most interesting (like there's a lot going on). \n",
    "\n",
    "On the other hand, what's going on in Navarres at 6000 years ago with sprouters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from bokeh.io import push_notebook, show, output_notebook\n",
    "from bokeh.layouts import gridplot, widgetbox, column# container for bokeh figure objects\n",
    "from bokeh.models.widgets import Dropdown\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.plotting import figure\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_interactive_chronology(sitename):\n",
    "    df = pol_df.loc[sitename, :]['group_pct'] #extract pollen percents for specified site\n",
    "    \n",
    "    # create a column data source for the plots to share\n",
    "    source = ColumnDataSource(data=df.reset_index().to_dict('list'))\n",
    "    \n",
    "    # container for bokeh figure objects\n",
    "    plots = [] \n",
    "    time_range=None\n",
    "    \n",
    "    TOOLS = \"ypan,ywheel_zoom\"\n",
    "    \n",
    "    def get_width(base, factor, plot_num):\n",
    "        # function to increase width of first plot, since this ends up narrowed\n",
    "        # due to being the only one with yaxis labels.\n",
    "        if plot_num > 0:\n",
    "            return base\n",
    "        else:\n",
    "            return int(round(base*(1+factor)))\n",
    "    \n",
    "    for i, group in enumerate(df.columns):\n",
    "        p = figure(tools=TOOLS, plot_width=get_width(150, .25, i), \n",
    "                   plot_height=500, y_range=time_range,\n",
    "                   title=group.title())\n",
    "        p.line(group, 'agebp', source=source)\n",
    "        if i == 0:\n",
    "            p.y_range.flipped = True\n",
    "            time_range = p.y_range\n",
    "        else:\n",
    "            p.yaxis.major_label_text_font_size = '0pt'\n",
    "                    \n",
    "        plots.append(p)\n",
    "   \n",
    "    p = gridplot([plots])\n",
    "    t = show(p, notebook_handle=True)\n",
    "                \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for s in pol_df.index.get_level_values(0).unique():\n",
    "    print s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pol_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loc[u'Charco da Candieira', :]['count_group_tot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Earliest date for Charco da Candieira:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def print_daterange(sitename):\n",
    "    df = pol_df.loc[sitename, :]['group_count']\n",
    "    latest = df.index.min()\n",
    "    earliest = df.index.max()\n",
    "    print 'earliest date: {0} yr BP'.format(earliest)\n",
    "    print 'latest date: {0} yr BP'.format(latest)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for s in pol_df.index.get_level_values(0).unique():\n",
    "    print s\n",
    "    print_daterange(s)\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_interactive_chronology(u'Algendar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pol_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Points of particular interest in time series (discussed in upgrade report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### San Rafael 4000 - 8000 yrs BP\n",
    "Big variation in grasses shrubs and sprouters around the time it is thought agriculture reached Iberia (6500 yrs BP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_print_chronology(u'San Rafael', 8500, 1000, figlabel='A', save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Navarres 6000 - 7000 yrs BP\n",
    "~ 200 year oscillation in percentages of grass and seeders 6400 - 6800 yrs BP, followed by sudden and sustained increase in sprouters after 6400 yrs BP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_print_chronology(u'NavarrÃ©s', 10500, 3000, figlabel='B', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 4. Apply the LRA to infer land-cover proportion from pollen abundance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. TODO Output plant functional group time-series for each study site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEMP Time-series of proportion of total pollen abundance for each plant functional group\n",
    "- NOTE at present (May 18) I've not implemented the LRA yet so will output pollen _abundance_ between species, rather than using the LRA's method of correcting for the variance in pollen produced by different species.\n",
    "- This is to get a preliminary model off the ground and should be corrected for as a priority."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pollen chronologies for study sites, and mappings to land cover classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'epd_data' not in locals():\n",
    "    import matplotlib \n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    # made in section 2 above\n",
    "    epd_data = pd.read_pickle('epd_data.pkl')\n",
    "    \n",
    "if 'mapped_species' not in locals():\n",
    "    # made in section 3 above\n",
    "    mapped_species = pd.read_csv('species_to_landcover_mapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print epd_data.head()\n",
    "print epd_data[epd_data.pcount>2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note the very high counts for san_rafael. Are these realistic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print epd_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data = epd_data.reset_index().merge(mapped_species.drop('varname', axis=1), on='varcode', how='left')\n",
    "epd_data = epd_data.dropna()\n",
    "print epd_data.shape\n",
    "print epd_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollen_abundance = epd_data.groupby(['sitecode', 'e_', 'agebp', 'lct']).sum().unstack(3)\n",
    "pollen_abundance = pollen_abundance.fillna(0)\n",
    "pollen_abundance.loc[:,('pcount', 'total')] = pollen_abundance.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollen_abundance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert abundance to proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in pollen_abundance.pcount.columns:\n",
    "    if c <> 'total':\n",
    "        pollen_abundance.loc[:,('pprop', c)] = pollen_abundance.loc[:, ('pcount', c)]/pollen_abundance.loc[:, ('pcount', 'total')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollen_abundance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a quick look at the data to check it seems reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "pollen_abundance.loc[('navarres',  471), 'pprop'].plot(ax=ax)\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write processed pollen proportion data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollen_abundance.to_pickle('pollen_timeseries.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the above are pollen _proportion_ time series. These can be used as proportions feeding into an NLM. See the `/home/andrew/Dropbox/codes/python/notebooks/modified_random_clusters/implement_modified_random_clusters.html` for details\n",
    "\n",
    "#### TO move across to MRC notebook\n",
    "notebook for details of Supposing I start simulating Navarres from 7000 yrs BP, that gives me the following starting proportions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to find the nearest value to a given value in a numpy array\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav_dat = pollen_abundance.loc[('navarres',  471), 'pprop']\n",
    "nav_initial = nav_dat.loc[find_nearest(nav_dat.index.values, 7000)]\n",
    "print nav_initial\n",
    "#print find_nearest(nav_dat.index.values, 7000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jan 2019 -- Add time derivatives to timeseries dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollen_abundance = pd.read_pickle('pollen_timeseries.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollen_abundance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollen_abundance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollen_abundance['pprop'].xs('albufera_alcudia', level='sitecode').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to work out how to calculate, for each core, the pollen proportion slope with respect to the agebp index. This can be gathered as a new dataframe with the same MultiIndex as `pollen_abundance['pprop']`. This can then be joined back into `pollen_abundance` as `pollen_abundance['pprop_prime']`. The gradient of this will give `pollen_abundance['pprop_prime_prime']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pollen_abundance.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Rough working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Correlations between variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's look at how the counts of different groups correlate with each other within each study site through time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_epd_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['group_pct']['grass'].loc['Sanabria Marsh'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df.loc[u'NavarrÃ©s''Sanabria Marsh', :]['count_group_tot'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Are there clusters we can find in the counts of different pollen? Could investigate using KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pollen_conts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pollen_conts['pollen_pct']['mean'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nav_pine = nav_dat[nav_dat.varname=='Pinus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nav_pine['count'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nav_pine['pollen_pct'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nav_dat[nav_dat.varname=='Concentration spikes'].pollen_pct.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### TODO General theory to look up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Looking at understanding pollen spikes\n",
    "https://quantpalaeo.wordpress.com/2017/07/28/pollen-spikes/\n",
    "\n",
    "Calculating deposition rates\n",
    "http://www.europeanpollendatabase.net/wiki/lib/exe/fetch.php?media=epd_age-depth.pdf\n",
    "\n",
    "Using litholgy (depth) and and c14 (time) or (equivalently??) `depthcm` and `age` columns from `agebasis` table could be used to calculate sediment deposition rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "epd.ssites.append(762)\n",
    "epd.ssites.append(1260)\n",
    "epd.ssites.append(76)\n",
    "epd.ssites.append(560)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "epd.ssites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
