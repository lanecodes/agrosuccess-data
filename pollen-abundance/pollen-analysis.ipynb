{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstructing the land-cover of prehistoric landscapes\n",
    "\n",
    "The purpose of this notebook is to :\n",
    "1. Load pollen abundance time-series data extracted from the European Pollen Database for a selection of sites I am studying in the development of my PhD thesis.\n",
    "2. Explore, consider the limitations of, and clean that data.\n",
    "3. Support the systematic assignment of pollen types identified in the empirical data to the categorical land-cover types which will be represented in my simulation models. This is a form of modelling in itself, and serves as an abstraction couched in terms of the notion of a plant functional type. That is, plant _species_ which are postulated to be functionally identical as far as the model is concerned are assigned to the same plant functional group. This will be achieved using regular expressions to embelish the data in a pandas dataframe.\n",
    "4. Apply the Landscape Reconstruction Algorithm (LRA) to the pollen abundance data to infer the _proportion_ of landscape occupied from each plant functional group.\n",
    "5. Produce, for each of my empirical study sites, time-series of the proportion of landscape occupied for each of the functional groups represented in the model for the duration of time for which there is abundance data for each study site. This will be presented in the form of a `.csv` file and a plot for each study site. \n",
    "\n",
    "The only input required to run this notebook is a path to the file `site_pollen_abundance_ts.csv` which is output from [`epd-query`](https://github.com/lanecodes/epd-query)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "import unidecode\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "mpl.rcParams['font.family'] = 'CMU Sans Serif'\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#import seaborn as sns\n",
    "from ipywidgets import interact, fixed\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMP_DIR = Path('../tmp')\n",
    "OUTPUT_DIR = Path('../outputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load pollen data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data = pd.read_csv(TMP_DIR / 'site_pollen_abundance_ts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data.groupby(['sitename', 'e_']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore, condider the limitations of, and clean pollen core data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check numbers of samples in each core, narrow core selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data for one of the three Navarres cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav_dat = epd_data[epd_data['e_'] == 469]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav_dat.sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that much of the pollen recorded in the database for this sediment core corresponds to [pollen spike](https://quantpalaeo.wordpress.com/2017/07/28/pollen-spikes/), with `varcode` values of `conc.spk`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav_dat['sample_'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More troublingly, navares core 469, NAVA1 has only 15 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav2 = epd_data[epd_data['e_'] == 470]\n",
    "nav2['sample_'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav3 =  epd_data[epd_data['e_'] == 471]\n",
    "nav3['sample_'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going forward, I'll prefer NAVA3 over NAVA1 and NAVA2 since it contains more samples. If I find something which makes NAVA3 seem unreliable, I may reconsider. For now, drop NAVA1 and NAVA2 from the `epd_data` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data = epd_data[~epd_data['e_'].isin([469, 470])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at top ten pollen contributing species for each study site, remove sediment spike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_species(epd_data):\n",
    "    for ssite in epd_data['sitename'].unique():\n",
    "        print('\\n'+ssite)\n",
    "        df = epd_data[epd_data['sitename']==ssite]\n",
    "        df = df.groupby(['var_', 'varcode', 'varname']).agg({'count' : 'sum'})\n",
    "        print(df.sort_values(by='count', ascending=False).head(5))\n",
    "    del df\n",
    "\n",
    "print_top_species(epd_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navarres alone seems to have a lot of pollen spike in it. Also Monte Areo mire and Charco da Candieira have Lycopodium spike added. See [here](https://palynology.wordpress.com/2012/10/07/pollen-spike/) for background on pollen spike. To keep analyses between sites consistent, I will exclude these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_varcodes(df: pd.DataFrame, varcodes: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"Remove rows corresponding to specified varcodes from epd DF.\"\"\"\n",
    "    return df[~df['varcode'].isin(varcodes)]\n",
    "\n",
    "\n",
    "def remove_varcodes_test_df():\n",
    "    return pd.DataFrame({\n",
    "        'varcode': ['goodvar1', 'badvar1', 'badvar2', 'goodvar2'],\n",
    "        'count': np.random.randint(0, 4000, size=4)\n",
    "    })\n",
    "\n",
    "\n",
    "def test_remove_varcodes(test_df):\n",
    "    res_df = remove_varcodes(test_df, ['badvar1', 'badvar2'])\n",
    "    assert res_df.iloc[0]['varcode'] == 'goodvar1'\n",
    "    assert res_df.iloc[1]['varcode'] == 'goodvar2'\n",
    "    assert len(res_df.index) == 2\n",
    "    \n",
    "test_remove_varcodes(remove_varcodes_test_df())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_pollen_spike = True\n",
    "if exclude_pollen_spike:\n",
    "    epd_data = remove_varcodes(\n",
    "        epd_data, ['Spi/tab', 'Lyc(ad)', 'Lyc(ct)', 'Lyc']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also note that San Rafael has a significant proportion of Botryococcus in its samples. This is a type of green algae. Since this doesn't correspond to any _land_ plant species, we exclude it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aquatic_plant_codes = [\n",
    "    'Bry',\n",
    "    'Zyg-T',\n",
    "    'Spr-T',\n",
    "    'Pot',      # Potamogeton, aquatic plant\n",
    "    'Clo.i-T',  # Closterium idiosporum, green algae\n",
    "    'Spi.cf.s', # Spirogyra cf. scrobiculata, green algae\n",
    "    'Trl.s',    # Trilete spore(s),  not from modern terrestrial plant\n",
    "]\n",
    "\n",
    "exclude_non_land_plants = True\n",
    "if exclude_non_land_plants:\n",
    "    epd_data = remove_varcodes(epd_data, aquatic_plant_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identified lots of moss (Sphagnum) in, e.g. Atxuri. Exclude this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_mosses = True\n",
    "if exclude_mosses:\n",
    "    epd_data = remove_varcodes(epd_data, ['Sph'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungal spores such as Glomus turn up in Navarres. Exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fungal_species_codes = [\n",
    "    'Glomus',\n",
    "    'Pos',  # Polyadosporites, fungal spore http://www.redalyc.org/html/454/45437346003/index.html\n",
    "]\n",
    "\n",
    "exclude_fungi = True\n",
    "if exclude_fungi:\n",
    "    epd_data = remove_varcodes(epd_data, fungal_species_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove records corresponding to pollen which could not be identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrecognised_species_codes = [\n",
    "    'Ind.unkn',  # found in navarres\n",
    "    'T16C',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_unrecognised = True\n",
    "if exclude_unrecognised:\n",
    "    epd_data = remove_varcodes(epd_data, unrecognised_species_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, `epd_data` contains entries for all:\n",
    "1. sediment cores\n",
    "2. samples (depths/ ages)\n",
    "3. species (careful to exclude pollen spike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Give each site an easily typed `sitecode` to refer to as an index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be convenient to be able to refer to sites as an index. To make these easy to type, create a `sitecode` column which strips out spaces and removes any unicode names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epd_data['sitename'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data['sitecode'] = (\n",
    "    epd_data['sitename']\n",
    "    .apply(unidecode.unidecode)\n",
    "    .str.replace(' ', '_')\n",
    "    .str.lower()\n",
    ")\n",
    "\n",
    "print(epd_data.sitecode.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I plan to use `sitename` as an index going forward because it's natural to think in terms of study sites. This means I don't need other information in the dataframe I take forward in my analyses at the study site level of detail. So this information can easily be rerieved if needs be when debugging, I save this to disk and remove the extra columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_meta_fields = ['sitecode', 'sitename', 'site_', 'sigle', 'e_', 'chron_']\n",
    "site_meta = epd_data.groupby(site_meta_fields).size().rename('num_records')\n",
    "site_meta.to_csv(TMP_DIR / 'site_metadata.csv', encoding='utf8', header=True)\n",
    "epd_data = epd_data.drop(\n",
    "    [x for x in site_meta_fields if x != 'sitecode'], axis=1\n",
    ")\n",
    "epd_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sample_` (a database key from the EPD) is also redundant at this point, since we can idenify each sample from its `agebp`. Similarly each variable (pollen species) is uniquely identified by its `varcode` so we can also drop `var_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data = epd_data.drop(['sample_', 'var_'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check `agebp` and `count` can be converted to `int` without loss of data, and do the conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_field_to_int(df: pd.DataFrame, field: str) -> pd.DataFrame:\n",
    "    \"\"\"Convert named float field to int if no data would be lost.\"\"\"\n",
    "    assert (~df[field].isna()).all(), f'missing data found in {field}'\n",
    "    assert ((df[field] - df[field].astype(int)) == 0).all(), (\n",
    "     f'casting {field} to int caused loss of data'\n",
    "    )\n",
    "    df[field] = df[field].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data = (\n",
    "    epd_data\n",
    "    .pipe(lambda df: convert_field_to_int(df, 'agebp'))\n",
    "    .pipe(lambda df: convert_field_to_int(df, 'count'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a unique index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data = epd_data.set_index(['sitecode', 'agebp', 'varcode']).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find index is unexpectedly not unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check which sites duplicates are coming from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data[epd_data.index.duplicated()].groupby(level=['sitecode']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_affected = 107 / len(epd_data.loc['charco_da_candieira'].index) * 100\n",
    "print(f'{round(pct_affected, 2):.2f}% of charco_da_candieira entries are duplicates')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As less than 1% of Charco da Candieira sample/ species combinations are affected, we will simply assume that where multiple entries are associated for a species in a single sample, the correct count is obtained by summing any duplicates. No other site's data are affected by this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_index_len = len(epd_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varcode_to_varname_df = (\n",
    "    epd_data.reset_index(level='varcode')[['varcode', 'varname']]\n",
    "    .drop_duplicates()\n",
    "    .set_index('varcode')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data = (\n",
    "    epd_data['count']\n",
    "    .groupby(level=['sitecode', 'agebp', 'varcode']).sum()\n",
    "    .to_frame()\n",
    "    .join(varcode_to_varname_df)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert initial_index_len - len(epd_data.index) == 107\n",
    "assert epd_data.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename `count` to avoid an understandable but irritating namespace collision with the `pd.Series.count` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data = epd_data.rename(columns={'count': 'pcount'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data.loc['navarres'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data.groupby(level=['sitecode', 'agebp']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`epd_data` is now prepped and ready to use for subsequent analyses. Serialise a csv file so it can be retrieved without rerunning the above cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data.to_csv(TMP_DIR / 'clean_epd_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TODO Relate identified pollen species with model-dependent plant functional types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    epd_data\n",
    "except NameError:\n",
    "    epd_data = (\n",
    "        pd.read_csv(TMP_DIR / 'clean_epd_data.csv')\n",
    "        .set_index(['sitecode', 'agebp', 'varcode'])\n",
    "    )   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify land-cover types with pollen species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve a list of unique `varname`-s found amongst the sediment cores analysed thus far in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_species = epd_data.reset_index()[['varname', 'varcode']].drop_duplicates()\n",
    "unique_species.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~Aim is to construct a list of dicts with keys `pattern` and `lct`. Intended to mean: if _this_ pattern is found in a species name, map it to _this_ land cover type. ~~\n",
    "\n",
    "Can't map individual species to individual land cover type. E.g. pine exists in both pine and transition forest. How to attribute \n",
    "\n",
    "how to distinguish a small area of pine forest's contribution from a large area of transition forest? They might generate similar amounts of pollen, but result from very different landscapes.\n",
    "\n",
    "Maybe I need to further simplify the land cover types I'd like to represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map land land cover types to species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Landcover types which are represented in my model are as follows:\n",
    "\n",
    "##### 1. Water/ Quarry\n",
    "No pollen produced\n",
    "\n",
    "##### 2. Burnt\n",
    "No pollen produced\n",
    "\n",
    "#### 3. Barley \n",
    "Grass pollen produced, belongs to the Poaceae (formerly known as Gramineae) family.\n",
    "\n",
    "None present at the start of a simulation\n",
    "\n",
    "#### 4. Wheat \n",
    "Grass pollen produced, belongs to the Poaceae (formerly known as Gramineae) family\n",
    "\n",
    "None present at the start of a simulation\n",
    "\n",
    "#### 5. Depleated Agricultural Land\n",
    "No pollen produced\n",
    "\n",
    "None present at the start of a simulation\n",
    "\n",
    "#### 6. Shrubland\n",
    "- Grasses (Poaceae, formerly Gramineae, family)\n",
    "- Juniper (Genus:\tJuniperus, belongs to cypress family Cupressaceae)\n",
    "\n",
    "#### 7. Pine forest\n",
    "Anything belonging to the pinus genera\n",
    "\n",
    "#### 9. Deciduous forest\n",
    "- Beech family, Fagaceae\n",
    "- Chestnut (Castanea genus)\n",
    "\n",
    "#### 10. Oak forest\n",
    "- Anything in quercus\n",
    "\n",
    "##### Comment on Transition Forest\n",
    "- Originally in model\n",
    "- No way to distinguish from pollen between pine forest, oak forest and transition forest. As it stands, it makes sense to integrate out the transition forest state, so we create the possibility of transitioning directly between pine and oak, subject to the kind of environmental conditions which would support transition forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_lct_maps = {    \n",
    "    # SHRUBLAND\n",
    "    # grasses\n",
    "    r'(.*(?i)Poaceae.*|.*(?i)Gramineae.*|.*(?i)Cerealia.*)' : 'shrubland',\n",
    "    # juniper\n",
    "    r'.*(?i)Juniperus.*' : 'shrubland',\n",
    "    # and cypress family\n",
    "    r'.*(?i)Cupressaceae.*' : 'shrubland',\n",
    "    # quillwort (prolific in Sanabria Marsh)\n",
    "    r'.*(?i)Isoetes.*' : 'shrubland',\n",
    "    # Goosefoot family (prolific in e.g. San Rafael)\n",
    "    r'.*(?i)Chenopodiaceae.*' : 'shrubland',\n",
    "    # Mugwort genus (prolific in e.g. San Rafael)\n",
    "    r'.*(?i)Artemisia.*' : 'shrubland',\n",
    "    # flowering plants in the same family as lettuce, dendelions etc\n",
    "    r'.*(?i)Cichorioideae.*' : 'shrubland',\n",
    "    # family of shrubby plants\n",
    "    r'.*(?i)Asteroideae.*' : 'shrubland',    \n",
    "    # sedge family (superficially resemble grasses)\n",
    "    r'.*(?i)Cyperaceae.*' : 'shrubland', # see e.g. Atxuri    \n",
    "    # heather\n",
    "    r'.*(?i)Calluna vulgaris.*' : 'shrubland', \n",
    "    # heather family\n",
    "    r'(.*(?i)Ericaceae.*|.*(?i)Erica-type.*|.*(?i)Erica arborea-type.*)' : 'shrubland', \n",
    "    #  celery, carrot, parsley family\n",
    "    r'.*(?i)Umbelliferae.*' : 'shrubland', \n",
    "    # celery and marthwort genus\n",
    "    r'.*(?i)Apium.*' : 'shrubland', \n",
    "    # box plant (shrubby tree)\n",
    "    r'.*(?i)Buxus.*' : 'shrubland',\n",
    "    # genus of flowering plants, buttercup genus\n",
    "    r'.*(?i)Ranunculus.*' : 'shrubland',\n",
    "    # doc/ sorrel genus\n",
    "    r'.*(?i)Rumex.*' : 'shrubland',\n",
    "     # bracken/ ferns. Associated with pine forest??\n",
    "    r'(.*(?i)Pteridium.*|.*(?i)Polypodium.*|.*(?i)Filicales.*)' : 'shrubland', \n",
    "    # genus of gymnosperm shrubs\n",
    "    r'.*(?i)Ephedra.*' : 'shrubland',    \n",
    "    # flowering plants found in wet regions\n",
    "    r'(.*(?i)Sparganium.*|.*(?i)Typha angustifolia.*)' : 'shrubland', \n",
    "    # plantain/ fleawort genus\n",
    "    r'.*(?i)Plantago.*' : 'shrubland',\n",
    "    # olive genus\n",
    "    r'.*(?i)Olea.*' : 'shrubland',\n",
    "    \n",
    "    # PINE FOREST\n",
    "    r'\\s*(?i)Pinus\\s*' : 'pine_forest',\n",
    "    \n",
    "    # DECIDUOUS FOREST\n",
    "    # chestnut\n",
    "    r'.*(?i)Castanea.*' : 'deciduous_forest',\n",
    "    # birch\n",
    "    r'.*(?i)Betula.*' : 'deciduous_forest',\n",
    "    # Beech family\n",
    "    r'.*(?i)Fagaceae.*' : 'deciduous_forest',\n",
    "    # Beech genus\n",
    "    r'.*(?i)Fagus.*' : 'deciduous_forest',\n",
    "    # Alder genus\n",
    "    r'.*(?i)Alnus.*' : 'deciduous_forest',\n",
    "    # Hazel\n",
    "    r'.*(?i)Corylus.*' : 'deciduous_forest',\n",
    "    # Willow\n",
    "    r'.*(?i)Salix.*' : 'deciduous_forest',  \n",
    "    # Hornbeam\n",
    "    r'.*(?i)Carpinus.*' : 'deciduous_forest',  \n",
    "    \n",
    "    # OAK FOREST\n",
    "    r'.*(?i)Quercus.*' : 'oak_forest'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function which, given a species name, returns a list of land cover types. h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lct(species_name, pol_lct_dict, verbose=False):\n",
    "    \"\"\"Given a species name, map it to a land cover type.\n",
    "    \n",
    "    Throw a ValueError if species name matches more than one land cover type.\n",
    "    \"\"\"\n",
    "    lcts = []\n",
    "    for r in pol_lct_dict.keys():\n",
    "        if re.match(r, species_name):\n",
    "            lcts.append(pol_lct_dict[r])\n",
    "            if verbose:\n",
    "                print(r + ' matches ' + species_name)\n",
    "    \n",
    "    if len(lcts) > 1:\n",
    "        # len(lcts)\n",
    "        raise ValueError('Species name {0} matched multiple land cover type '\\\n",
    "                         'regex strings: {1}'.format(species_name, lcts))\n",
    "    elif len(lcts) == 0:\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        return lcts[0]\n",
    "\n",
    "print(get_lct('Carpinus', pol_lct_maps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply `get_lct` to each species included in the chronology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_species['lct'] = unique_species.varname.apply(lambda x: get_lct(x, pol_lct_maps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_species = unique_species[unique_species['lct'].notnull()]\n",
    "mapped_species.to_csv(TMP_DIR / 'species_to_landcover_mapping.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate proportion of pollen, for each study site, accounted for by land-cover type mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each study site, find the overall percentage of pollen contributed by each species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pollen_by_site_species = epd_data.groupby([epd_data.index.get_level_values(0), 'varcode']).sum().reset_index(1)\n",
    "all_pollen_by_site = all_pollen_by_site_species.groupby(level=0).sum().rename(columns={'pcount':'site_total'})\n",
    "all_pollen_by_site_species = all_pollen_by_site_species.join(all_pollen_by_site)\n",
    "all_pollen_by_site = None # remove temporary dataframe used in join\n",
    "all_pollen_by_site_species['species_pct'] = all_pollen_by_site_species.pcount/all_pollen_by_site_species.site_total*100\n",
    "all_pollen_by_site_species = all_pollen_by_site_species.drop(['pcount', 'site_total'], axis=1).reset_index()\n",
    "print all_pollen_by_site_species.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add `varname` and `lct` coulmns from `unique_species`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge in species info\n",
    "all_pollen_by_site_species = all_pollen_by_site_species.merge(unique_species, on='varcode', how='left')\n",
    "# sort by site and percent pollen contributed by species\n",
    "all_pollen_by_site_species = all_pollen_by_site_species.sort_values(by=['sitecode','species_pct'], ascending=False).set_index('sitecode')\n",
    "# replace None with the string 'not_specified' in the joined in lct column\n",
    "all_pollen_by_site_species.lct = all_pollen_by_site_species.lct.fillna('not_specified')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print all_pollen_by_site_species.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_accounted_by_lct = all_pollen_by_site_species.reset_index().groupby(['sitecode', 'lct']).sum()\n",
    "pol_accounted_by_lct = pol_accounted_by_lct.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_accounted_by_lct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "pol_accounted_by_lct.plot(kind='bar', stacked=True, ax=ax)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unexplained_pollen = all_pollen_by_site_species[all_pollen_by_site_species.lct=='not_specified']\n",
    "for i in unexplained_pollen.index.unique():\n",
    "    print unexplained_pollen.loc[i].drop('lct', axis=1).head()\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proportions of pollen not falling into one of the groups represented in the model above is deeped acceptable, i.e. at least 90% of pollen for simulated study sites is attributed to a modelled land cover type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REPLACE Consider only most abundant species overall across study sites\n",
    "- At this point, each species in a list of the identified species with the most pollen accross all sites is matched manually to one of grass, seeder, sprouter, shrub or exclude in an external csv file. \n",
    "- This is sub-optimal as the files are edited manually, making it difficult for someone else to track the logic -- we should exploit the readability of Python to make this explicit.\n",
    "- Instead, propose to use a series of regular expressions to create a map between species and plant functional type\n",
    "- Target should be to get at least 90% of pollen for each site accounted for in one of the landcover types I propose as part of my model. \n",
    "- Since the grouping of species into different functional types effectievly defines a model, it should be set up so a list of regular expressions conditions can be passed to a function to apply them and return the resulting dataframe in the expected format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_species(n):\n",
    "    #return a dataframe giving top n species \n",
    "    # for all cores in epd_data   \n",
    "    res = pd.DataFrame(columns=['var_', 'varname', 'count', 'sitename'])\n",
    "    for ssite in epd_data.sitename.unique():\n",
    "        df = epd_data[epd_data.sitename==ssite]\n",
    "        df = df.groupby(['var_', 'varname']).agg({'count' : 'sum'}).reset_index()\n",
    "        df['sitename'] = ssite\n",
    "        df = df.sort_values(by='count', ascending=False).head(n)\n",
    "        res = res.append(df)\n",
    "        res = res.reset_index(drop=True)\n",
    "        res.var_ = res.var_.astype('int')\n",
    "        res = res[['sitename', 'var_', 'varname', 'count']]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_species = get_top_species(10)\n",
    "top_species = top_species.groupby(['var_', 'varname']).agg({'sitename' : 'count'})\n",
    "top_species = top_species.sort_values('sitename', ascending=False)\n",
    "top_species.columns = ['sitecount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print top_species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add to this list any variables which are some form of pinus which have not already been identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinus_species = epd_data[epd_data.varname.str.lower().str.contains('pinus')][['var_', 'varname']].drop_duplicates()\n",
    "print pinus_species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the Carpinus types (these are actually in the Birch family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinus_species = pinus_species.drop([438, 8], axis=0).set_index('var_')\n",
    "print pinus_species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find pinus species not already listed in `top_species`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinus_species = pinus_species.join(top_species.reset_index(1)['sitecount'], how='left')\n",
    "pinus_species = pinus_species[pinus_species.sitecount.isnull()].fillna(0)\n",
    "pinus_species = pinus_species.reset_index().set_index(['var_','varname'])\n",
    "print pinus_species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append to `top_species`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_species = top_species.append(pinus_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_species.to_csv('top_species.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### REPLACE Edit list of species manually outside of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_species = pd.read_csv('top_species_edited.csv',\n",
    "                         index_col='var_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Prepare top species for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_species[(top_species.group<>'exclude') & (top_species.group.notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "epd_data = epd_data.join(top_species['group'], on='var_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "epd_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Get total pollen contributed by each group for each entity and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "group_counts = epd_data.groupby(['e_', 'sample_', 'group']).agg({'count' : 'sum'})\n",
    "epd_data = epd_data.join(group_counts, on=['e_', 'sample_', 'group'], rsuffix='_group_tot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "group_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create a new dataframe, `top_epd_data` to store only those rows from `epd_data` where the entry corresponds to one of hte groups considered (shrub, sprouter, grass and seeder). First find unique combinations of values relevant for specifying pollen counts at the group level. This means dropping columns used for identifying species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_epd_data = epd_data.drop(['var_', 'count', 'varcode', 'varname', 'pollen_pct'], axis=1)\n",
    "top_epd_data = epd_data[['e_', 'sample_', 'agebp', 'site_', 'sitename', 'count_sample_tot', 'group']].drop_duplicates()\n",
    "top_epd_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Remove rows corresponding to excluded or unspecified groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_epd_data = top_epd_data[(top_epd_data.group<>'exclude') & (top_epd_data.group.notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_epd_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Join in total pollen counts by group from `group_counts` data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_epd_data = top_epd_data.join(group_counts, on=['e_', 'sample_', 'group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_epd_data['group_pct'] = top_epd_data['count']/top_epd_data.count_sample_tot*100\n",
    "top_epd_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_epd_data.columns = ['e_', 'sample_', 'agebp', 'site_', 'sitename', 'count_sample_tot',\n",
    "                      'group', 'count_group_tot', 'group_pct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_epd_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Finally pivot dataframe to provide easier access to data for plotting and statistical analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pol_df = top_epd_data.drop(['e_', 'sample_', 'site_', 'count_sample_tot'], axis=1)\n",
    "pol_df.columns = ['agebp', 'sitename', 'group', 'group_count', 'group_pct']\n",
    "pol_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pol_df = pol_df.set_index(['sitename', 'agebp', 'group'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Charco da Candieira contains multiple entries for three samples. At time of writing (4 days before upgrade report is due) I simply don't have time to debug this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pol_df[pol_df.index.duplicated(False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For now I'll do a quick and dirty exclusion of all but the first of each of these entries, but will need to address more carefully as a TODO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pol_df = pol_df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pol_df = pol_df[~pol_df.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pol_df[pol_df.index.duplicated(False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pol_df = pol_df.unstack()\n",
    "pol_df = pol_df.fillna(0)\n",
    "pol_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pol_df.to_pickle('pol_df.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Plot pollen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    pol_df\n",
    "except NameError:\n",
    "    pol_df = pd.read_pickle('pol_df.pickle')\n",
    "    print 'pol_df read from file.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### For print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_print_chronology(sitename, earliest, latest, figlabel=None, save=False):\n",
    "    df = pol_df.loc[sitename, :]['group_pct'] #extract pollen percents for specified site\n",
    "    df = df[(df.index <= earliest) & (df.index >= latest)] # exclude samples from earlier that specified years before present\n",
    "    \n",
    "    def tweak_pct_ticks(axis, pct_vals):\n",
    "        max_pct = int(round(pct_vals.max()*1.1))\n",
    "        \n",
    "        def get_increments(maximum):\n",
    "            while maximum%4 <> 0:\n",
    "                maximum += 1\n",
    "            return [maximum/4 * i for i in range(5)]\n",
    "        \n",
    "        increments = get_increments(max_pct)\n",
    "        axis.set_xlim(0, increments.pop())\n",
    "        axis.xaxis.set_ticks(increments)\n",
    "        \n",
    "    def make_under_line_polygon(xx, yy, e, l):\n",
    "        line_vertices = np.column_stack((xx, yy))\n",
    "        leftmost_corners = np.array([[0, e], [0,l]])\n",
    "        vertices = np.concatenate((line_vertices, leftmost_corners))\n",
    "        return Polygon(vertices, True)       \n",
    "    \n",
    "    pollen_line_colour = '#145D85'\n",
    "    \n",
    "    f, axes = plt.subplots(1, len(df.columns), sharey=True)\n",
    "    for i, group in enumerate(df.columns):\n",
    "        xx = df[group].values\n",
    "        yy = df.index.values\n",
    "        axes[i].plot(xx,yy, color=pollen_line_colour)\n",
    "        axes[i].set_title(group.title())\n",
    "        axes[i].set_ylim([latest, earliest])\n",
    "        tweak_pct_ticks(axes[i], xx)\n",
    "        \n",
    "        poly = make_under_line_polygon(xx, yy, earliest, latest)\n",
    "        p = PatchCollection([poly], alpha=0.4)\n",
    "        p.set_color(pollen_line_colour)\n",
    "        axes[i].add_collection(p)\n",
    "        \n",
    "        if i == 0:\n",
    "            axes[i].set_ylabel('yrs BP', fontsize=13)\n",
    "            if figlabel:\n",
    "                xticks = axes[i].get_xticks()\n",
    "                yticks = axes[i].get_yticks()\n",
    "                xtick_scale = xticks[1]-xticks[0]\n",
    "                ytick_scale = yticks[1]-yticks[0]\n",
    "\n",
    "                axes[i].text(-1.15*xtick_scale, latest-0.5*ytick_scale, \n",
    "                             figlabel,\n",
    "                             fontdict = {'weight': 'bold',\n",
    "                                         'size': 16}\n",
    "                            )\n",
    "    \n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.subplots_adjust(hspace=0, wspace=0)\n",
    "    f.text(0.51, 0.02, '% contribution to total pollen sample', ha='center', fontsize=13)\n",
    "    #plt.suptitle(sitename, y=1.05, fontsize=12)\n",
    "    \n",
    "    if save:\n",
    "        d = os.path.join('plots')\n",
    "        if not os.path.exists(d):\n",
    "            os.makedirs(d)\n",
    "\n",
    "        plt.savefig(os.path.join('plots',\n",
    "                                 (sitename.replace(' ', '_')+'_'\n",
    "                                 +str(earliest)+'-'+str(latest)+'.pdf')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for s in pol_df.index.get_level_values(0).unique():\n",
    "    print s\n",
    "    plot_print_chronology(s, 15000, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Of these, to my eye, San Rafael looks the most interesting (like there's a lot going on). \n",
    "\n",
    "On the other hand, what's going on in Navarres at 6000 years ago with sprouters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from bokeh.io import push_notebook, show, output_notebook\n",
    "from bokeh.layouts import gridplot, widgetbox, column# container for bokeh figure objects\n",
    "from bokeh.models.widgets import Dropdown\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.plotting import figure\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_interactive_chronology(sitename):\n",
    "    df = pol_df.loc[sitename, :]['group_pct'] #extract pollen percents for specified site\n",
    "    \n",
    "    # create a column data source for the plots to share\n",
    "    source = ColumnDataSource(data=df.reset_index().to_dict('list'))\n",
    "    \n",
    "    # container for bokeh figure objects\n",
    "    plots = [] \n",
    "    time_range=None\n",
    "    \n",
    "    TOOLS = \"ypan,ywheel_zoom\"\n",
    "    \n",
    "    def get_width(base, factor, plot_num):\n",
    "        # function to increase width of first plot, since this ends up narrowed\n",
    "        # due to being the only one with yaxis labels.\n",
    "        if plot_num > 0:\n",
    "            return base\n",
    "        else:\n",
    "            return int(round(base*(1+factor)))\n",
    "    \n",
    "    for i, group in enumerate(df.columns):\n",
    "        p = figure(tools=TOOLS, plot_width=get_width(150, .25, i), \n",
    "                   plot_height=500, y_range=time_range,\n",
    "                   title=group.title())\n",
    "        p.line(group, 'agebp', source=source)\n",
    "        if i == 0:\n",
    "            p.y_range.flipped = True\n",
    "            time_range = p.y_range\n",
    "        else:\n",
    "            p.yaxis.major_label_text_font_size = '0pt'\n",
    "                    \n",
    "        plots.append(p)\n",
    "   \n",
    "    p = gridplot([plots])\n",
    "    t = show(p, notebook_handle=True)\n",
    "                \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for s in pol_df.index.get_level_values(0).unique():\n",
    "    print s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pol_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loc[u'Charco da Candieira', :]['count_group_tot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Earliest date for Charco da Candieira:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def print_daterange(sitename):\n",
    "    df = pol_df.loc[sitename, :]['group_count']\n",
    "    latest = df.index.min()\n",
    "    earliest = df.index.max()\n",
    "    print 'earliest date: {0} yr BP'.format(earliest)\n",
    "    print 'latest date: {0} yr BP'.format(latest)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for s in pol_df.index.get_level_values(0).unique():\n",
    "    print s\n",
    "    print_daterange(s)\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_interactive_chronology(u'Algendar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pol_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Points of particular interest in time series (discussed in upgrade report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### San Rafael 4000 - 8000 yrs BP\n",
    "Big variation in grasses shrubs and sprouters around the time it is thought agriculture reached Iberia (6500 yrs BP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_print_chronology(u'San Rafael', 8500, 1000, figlabel='A', save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Navarres 6000 - 7000 yrs BP\n",
    "~ 200 year oscillation in percentages of grass and seeders 6400 - 6800 yrs BP, followed by sudden and sustained increase in sprouters after 6400 yrs BP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_print_chronology(u'Navarrs', 10500, 3000, figlabel='B', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 4. Apply the LRA to infer land-cover proportion from pollen abundance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. TODO Output plant functional group time-series for each study site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEMP Time-series of proportion of total pollen abundance for each plant functional group\n",
    "- NOTE at present (May 18) I've not implemented the LRA yet so will output pollen _abundance_ between species, rather than using the LRA's method of correcting for the variance in pollen produced by different species.\n",
    "- This is to get a preliminary model off the ground and should be corrected for as a priority."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pollen chronologies for study sites, and mappings to land cover classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'epd_data' not in locals():\n",
    "    import matplotlib \n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    # made in section 2 above\n",
    "    epd_data = pd.read_pickle('epd_data.pkl')\n",
    "    \n",
    "if 'mapped_species' not in locals():\n",
    "    # made in section 3 above\n",
    "    mapped_species = pd.read_csv('species_to_landcover_mapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print epd_data.head()\n",
    "print epd_data[epd_data.pcount>2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note the very high counts for san_rafael. Are these realistic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print epd_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_data = epd_data.reset_index().merge(mapped_species.drop('varname', axis=1), on='varcode', how='left')\n",
    "epd_data = epd_data.dropna()\n",
    "print epd_data.shape\n",
    "print epd_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollen_abundance = epd_data.groupby(['sitecode', 'e_', 'agebp', 'lct']).sum().unstack(3)\n",
    "pollen_abundance = pollen_abundance.fillna(0)\n",
    "pollen_abundance.loc[:,('pcount', 'total')] = pollen_abundance.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollen_abundance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert abundance to proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in pollen_abundance.pcount.columns:\n",
    "    if c <> 'total':\n",
    "        pollen_abundance.loc[:,('pprop', c)] = pollen_abundance.loc[:, ('pcount', c)]/pollen_abundance.loc[:, ('pcount', 'total')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollen_abundance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a quick look at the data to check it seems reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "pollen_abundance.loc[('navarres',  471), 'pprop'].plot(ax=ax)\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write processed pollen proportion data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollen_abundance.to_pickle('pollen_timeseries.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the above are pollen _proportion_ time series. These can be used as proportions feeding into an NLM. See the `/home/andrew/Dropbox/codes/python/notebooks/modified_random_clusters/implement_modified_random_clusters.html` for details\n",
    "\n",
    "#### TO move across to MRC notebook\n",
    "notebook for details of Supposing I start simulating Navarres from 7000 yrs BP, that gives me the following starting proportions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to find the nearest value to a given value in a numpy array\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav_dat = pollen_abundance.loc[('navarres',  471), 'pprop']\n",
    "nav_initial = nav_dat.loc[find_nearest(nav_dat.index.values, 7000)]\n",
    "print nav_initial\n",
    "#print find_nearest(nav_dat.index.values, 7000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jan 2019 -- Add time derivatives to timeseries dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollen_abundance = pd.read_pickle('pollen_timeseries.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollen_abundance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollen_abundance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollen_abundance['pprop'].xs('albufera_alcudia', level='sitecode').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to work out how to calculate, for each core, the pollen proportion slope with respect to the agebp index. This can be gathered as a new dataframe with the same MultiIndex as `pollen_abundance['pprop']`. This can then be joined back into `pollen_abundance` as `pollen_abundance['pprop_prime']`. The gradient of this will give `pollen_abundance['pprop_prime_prime']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pollen_abundance.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Rough working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Correlations between variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's look at how the counts of different groups correlate with each other within each study site through time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_epd_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['group_pct']['grass'].loc['Sanabria Marsh'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df.loc[u'Navarrs''Sanabria Marsh', :]['count_group_tot'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Are there clusters we can find in the counts of different pollen? Could investigate using KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pollen_conts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pollen_conts['pollen_pct']['mean'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nav_pine = nav_dat[nav_dat.varname=='Pinus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nav_pine['count'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nav_pine['pollen_pct'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nav_dat[nav_dat.varname=='Concentration spikes'].pollen_pct.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### TODO General theory to look up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Looking at understanding pollen spikes\n",
    "https://quantpalaeo.wordpress.com/2017/07/28/pollen-spikes/\n",
    "\n",
    "Calculating deposition rates\n",
    "http://www.europeanpollendatabase.net/wiki/lib/exe/fetch.php?media=epd_age-depth.pdf\n",
    "\n",
    "Using litholgy (depth) and and c14 (time) or (equivalently??) `depthcm` and `age` columns from `agebasis` table could be used to calculate sediment deposition rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "epd.ssites.append(762)\n",
    "epd.ssites.append(1260)\n",
    "epd.ssites.append(76)\n",
    "epd.ssites.append(560)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "epd.ssites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
